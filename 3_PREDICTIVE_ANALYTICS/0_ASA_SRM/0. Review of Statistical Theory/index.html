
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://example.com/3_PREDICTIVE_ANALYTICS/0_ASA_SRM/0.%20Review%20of%20Statistical%20Theory/">
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-8.5.10">
    
    
      
        <title>Review of Statistical Theory - Exam Notes</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.975780f9.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.2505c338.min.css">
        
          
          
          <meta name="theme-color" content="#000000">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../config/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#review-of-statistical-theory" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Exam Notes" class="md-header__button md-logo" aria-label="Exam Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Exam Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Review of Statistical Theory
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Exam Notes" class="md-nav__button md-logo" aria-label="Exam Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Exam Notes
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1">
          Introductory
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Introductory" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          Introductory
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../1_INTRODUCTORY/0.%20Review%20of%20Mathematics/" class="md-nav__link">
        Review of Mathematics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Placeholder/" class="md-nav__link">
        ASA P
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Placeholder/" class="md-nav__link">
        ASA FM
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_4" type="checkbox" id="__nav_1_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1_4">
          ASA IFM
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA IFM" data-md-level="2">
        <label class="md-nav__title" for="__nav_1_4">
          <span class="md-nav__icon md-icon"></span>
          ASA IFM
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_4_1" type="checkbox" id="__nav_1_4_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1_4_1">
          Derivatives
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Derivatives" data-md-level="3">
        <label class="md-nav__title" for="__nav_1_4_1">
          <span class="md-nav__icon md-icon"></span>
          Derivatives
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../1_INTRODUCTORY/2_ASA_IFM/1.%20Derivatives/1.%20Introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../1_INTRODUCTORY/2_ASA_IFM/1.%20Derivatives/3.%20Options/" class="md-nav__link">
        Options
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../1_INTRODUCTORY/2_ASA_IFM/1.%20Derivatives/5.%20Binomial%20Model/" class="md-nav__link">
        Binomial Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../1_INTRODUCTORY/2_ASA_IFM/1.%20Derivatives/6.%20Black%20Scholes%20Model/" class="md-nav__link">
        Black Scholes Model
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_4_2" type="checkbox" id="__nav_1_4_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1_4_2">
          Corporate Finance
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Corporate Finance" data-md-level="3">
        <label class="md-nav__title" for="__nav_1_4_2">
          <span class="md-nav__icon md-icon"></span>
          Corporate Finance
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../1_INTRODUCTORY/2_ASA_IFM/3.%20Corporate%20Finance/3.%20Risk%20Measures/" class="md-nav__link">
        Risk Measures
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Actuarial Mathematics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Actuarial Mathematics" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Actuarial Mathematics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_1" type="checkbox" id="__nav_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_1">
          ASA FAMS
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA FAMS" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          ASA FAMS
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/0.%20Short%20Term%20Insurance/" class="md-nav__link">
        Short Term Insurance
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/1.%20Review%20of%20Probability%20Theory/" class="md-nav__link">
        Review of Probability Theory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/2.%20Frequency%20Models/" class="md-nav__link">
        Frequency Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/3.%20Severity%20Models/" class="md-nav__link">
        Severity Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/4.%20Policy%20Modifications/" class="md-nav__link">
        Policy Modifications
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/5.%20Aggregate%20Models/" class="md-nav__link">
        Aggregate Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/6.%20Loss%20Reserving/" class="md-nav__link">
        Loss Reserving
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/7.%20Ratemaking/" class="md-nav__link">
        Ratemaking
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/8.%20Model%20Estimation/" class="md-nav__link">
        Model Estimation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/9.%20Credibility%20Theory/" class="md-nav__link">
        Credibility Theory
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_2" type="checkbox" id="__nav_2_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_2">
          ASA FAML
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA FAML" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          ASA FAML
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/0.%20Long%20Term%20Insurance/" class="md-nav__link">
        Long Term Insurance
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/1.%20Survival%20Models/" class="md-nav__link">
        Survival Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/2.%20Life%20Tables/" class="md-nav__link">
        Life Tables
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/3.%20Life%20Assurances/" class="md-nav__link">
        Life Assurances
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/4.%20Life%20Annuities/" class="md-nav__link">
        Life Annuities
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/5.%20Variable%20Benefits/" class="md-nav__link">
        Variable Benefits
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/6.%20Premiums/" class="md-nav__link">
        Premiums
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/7.%20Reserves/" class="md-nav__link">
        Reserves
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/8.%20Model%20Estimation/" class="md-nav__link">
        Model Estimation
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_3" type="checkbox" id="__nav_2_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_3">
          ASA ALTAM
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA ALTAM" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_3">
          <span class="md-nav__icon md-icon"></span>
          ASA ALTAM
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/1.%20Multi%20Life%20Models/" class="md-nav__link">
        Multi Life Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/2.%20Multi%20Decrement%20Models/" class="md-nav__link">
        Multi Decrement Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/3.%20Multi%20State%20Models/" class="md-nav__link">
        Multi State Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/4.%20Multi%20State%20Applications/" class="md-nav__link">
        Multi State Applications
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/5.%20Profit%20Testing/" class="md-nav__link">
        Profit Testing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/6.%20Universal%20Life/" class="md-nav__link">
        Universal Life
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/7.%20Embedded%20Options/" class="md-nav__link">
        Embedded Options
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/8.%20Pensions/" class="md-nav__link">
        Pensions
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Predictive Analytics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Predictive Analytics" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Predictive Analytics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1" type="checkbox" id="__nav_3_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1">
          ASA SRM
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA SRM" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          ASA SRM
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Review of Statistical Theory
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Review of Statistical Theory
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview-of-statistics" class="md-nav__link">
    Overview of Statistics
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample-statistics" class="md-nav__link">
    Sample Statistics
  </a>
  
    <nav class="md-nav" aria-label="Sample Statistics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#central-tendency" class="md-nav__link">
    Central Tendency
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dispersion" class="md-nav__link">
    Dispersion
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bivariate" class="md-nav__link">
    Bivariate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bias-variance" class="md-nav__link">
    Bias Variance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#degrees-of-freedom" class="md-nav__link">
    Degrees of Freedom
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampling-distribution" class="md-nav__link">
    Sampling Distribution
  </a>
  
    <nav class="md-nav" aria-label="Sampling Distribution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#standard-normal-distribution" class="md-nav__link">
    Standard Normal Distribution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#t-distribution" class="md-nav__link">
    t-Distribution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chi-squared-distribution" class="md-nav__link">
    Chi-Squared Distribution
  </a>
  
    <nav class="md-nav" aria-label="Chi-Squared Distribution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sample-variance" class="md-nav__link">
    Sample Variance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reformulated-t" class="md-nav__link">
    Reformulated t
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goodness-of-fit" class="md-nav__link">
    Goodness of fit
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#f-distribution" class="md-nav__link">
    F-Distribution
  </a>
  
    <nav class="md-nav" aria-label="F-Distribution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#equality-of-variance" class="md-nav__link">
    Equality of Variance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#anova" class="md-nav__link">
    ANOVA
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statistical-inference" class="md-nav__link">
    Statistical Inference
  </a>
  
    <nav class="md-nav" aria-label="Statistical Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#confidence-interval" class="md-nav__link">
    Confidence Interval
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hypothesis-testing" class="md-nav__link">
    Hypothesis Testing
  </a>
  
    <nav class="md-nav" aria-label="Hypothesis Testing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sources-of-error" class="md-nav__link">
    Sources of Error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test-statistics" class="md-nav__link">
    Test Statistics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#link-to-confidence-intervals" class="md-nav__link">
    Link to Confidence Intervals
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#maximum-likelihood-estimation" class="md-nav__link">
    Maximum Likelihood Estimation
  </a>
  
    <nav class="md-nav" aria-label="Maximum Likelihood Estimation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#asymptotic-normality" class="md-nav__link">
    Asymptotic Normality
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practical-tips" class="md-nav__link">
    Practical Tips
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#method-of-moments" class="md-nav__link">
    Method of Moments
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../1.%20Statistical%20Learning/" class="md-nav__link">
        Statistical Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../2.%20Simple%20Linear%20Regression/" class="md-nav__link">
        Simple Linear Regression
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../3.%20Multiple%20Linear%20Regression/" class="md-nav__link">
        Multiple Linear Regression
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../4.%20Linear%20Regression%20Assumptions/" class="md-nav__link">
        Linear Regression Assumptions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../5.%20Model%20Selection/" class="md-nav__link">
        Model Selection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../6.%20Generalized%20Linear%20Models/" class="md-nav__link">
        Generalized Linear Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../7.%20Tree%20Models/" class="md-nav__link">
        Tree Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../8.%20Principal%20Components/" class="md-nav__link">
        Principal Components
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../9.%20Clustering/" class="md-nav__link">
        Clustering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../10.%20Time%20Series/" class="md-nav__link">
        Time Series
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_2" type="checkbox" id="__nav_3_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_2">
          ASA PA
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA PA" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_2">
          <span class="md-nav__icon md-icon"></span>
          ASA PA
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1_ASA_PA/0_OVERVIEW/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview-of-statistics" class="md-nav__link">
    Overview of Statistics
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample-statistics" class="md-nav__link">
    Sample Statistics
  </a>
  
    <nav class="md-nav" aria-label="Sample Statistics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#central-tendency" class="md-nav__link">
    Central Tendency
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dispersion" class="md-nav__link">
    Dispersion
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bivariate" class="md-nav__link">
    Bivariate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bias-variance" class="md-nav__link">
    Bias Variance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#degrees-of-freedom" class="md-nav__link">
    Degrees of Freedom
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampling-distribution" class="md-nav__link">
    Sampling Distribution
  </a>
  
    <nav class="md-nav" aria-label="Sampling Distribution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#standard-normal-distribution" class="md-nav__link">
    Standard Normal Distribution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#t-distribution" class="md-nav__link">
    t-Distribution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chi-squared-distribution" class="md-nav__link">
    Chi-Squared Distribution
  </a>
  
    <nav class="md-nav" aria-label="Chi-Squared Distribution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sample-variance" class="md-nav__link">
    Sample Variance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reformulated-t" class="md-nav__link">
    Reformulated t
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goodness-of-fit" class="md-nav__link">
    Goodness of fit
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#f-distribution" class="md-nav__link">
    F-Distribution
  </a>
  
    <nav class="md-nav" aria-label="F-Distribution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#equality-of-variance" class="md-nav__link">
    Equality of Variance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#anova" class="md-nav__link">
    ANOVA
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statistical-inference" class="md-nav__link">
    Statistical Inference
  </a>
  
    <nav class="md-nav" aria-label="Statistical Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#confidence-interval" class="md-nav__link">
    Confidence Interval
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hypothesis-testing" class="md-nav__link">
    Hypothesis Testing
  </a>
  
    <nav class="md-nav" aria-label="Hypothesis Testing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sources-of-error" class="md-nav__link">
    Sources of Error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test-statistics" class="md-nav__link">
    Test Statistics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#link-to-confidence-intervals" class="md-nav__link">
    Link to Confidence Intervals
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#maximum-likelihood-estimation" class="md-nav__link">
    Maximum Likelihood Estimation
  </a>
  
    <nav class="md-nav" aria-label="Maximum Likelihood Estimation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#asymptotic-normality" class="md-nav__link">
    Asymptotic Normality
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practical-tips" class="md-nav__link">
    Practical Tips
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#method-of-moments" class="md-nav__link">
    Method of Moments
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="review-of-statistical-theory"><strong>Review of Statistical Theory</strong><a class="headerlink" href="#review-of-statistical-theory" title="Permanent link">&para;</a></h1>
<p>This section assumes some basic knowledge on <strong>Probability Theory</strong>, which can be found under another set of notes covering a <a href="../../2. Actuarial Mathematics/ASA-FAMS/1. Review of Probability Theory.md">Review of Probability Theory</a>.</p>
<h2 id="overview-of-statistics"><strong>Overview of Statistics</strong><a class="headerlink" href="#overview-of-statistics" title="Permanent link">&para;</a></h2>
<p>Statistics is a discipline revolving around data.</p>
<p>A <strong>Population</strong> refers to the <em>theoretical</em> set of <strong>all possible</strong> data of the event of interest. The goal of statistics is to determine certain attributes that <strong>summarizes or describes</strong> the population, known as <strong>Parameters</strong>.</p>
<p>However, it is impossible to study the entire population at once, thus a <strong>subset of the population</strong> is studied instead, known as <strong>Sample</strong>. Attributes that summarize or describe the sample are known as <strong>Statistics</strong>.</p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>In practice, there are many different sampling methods that may result in vastly different samples. That is beyond the scope of this exam.</p>
</div>
<p>Ideally, the sample is <strong>representative</strong> of the population, which means that findings from the sample can be applied to the population as a whole. This means that the sample statistics can be used <strong>estimate</strong> population parameters.</p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Time is also a key consideration - observations from a time period closer to the experiment are definitely more representative.</p>
</div>
<p>We distinguish between the two (when they have the same notation) through the <strong>Hat accent</strong> (^) - Population Parameters are their written <strong>without the hat</strong> (<span class="arithmatex">\(x\)</span>) while their corresponding sample statistics are written <strong>with the hat</strong> (<span class="arithmatex">\(\hat{x}\)</span>).</p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>For more common statistics, they typically have their own unique notation. It is important to recognise both notations.</p>
</div>
<h2 id="sample-statistics"><strong>Sample Statistics</strong><a class="headerlink" href="#sample-statistics" title="Permanent link">&para;</a></h2>
<h3 id="central-tendency"><strong>Central Tendency</strong><a class="headerlink" href="#central-tendency" title="Permanent link">&para;</a></h3>
<p>The first set of Parameters &amp; Statistics are concerned with <strong>Central Tendency</strong>, which is a measure of where the centre of the distribution is, to be used as a <strong>representative value</strong>.</p>
<p>The most common measure is the <strong>Mean</strong>, which is the sum of all observations divided by the number of observations:</p>
<div class="arithmatex">\[
\begin{array}{|c|c|}
\hline
    \text{Population Mean} &amp;
    \text{Sample Mean} \\
\hline
    \displaystyle{\mu_{x} = \sum x_{i} \cdot P(x_{i})} &amp;
    \displaystyle{\bar{x} = \frac{1}{n} \sum x_{i}} \\
\hline
\end{array}
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The above is more formally known as the <strong>Arithmetic Mean</strong>. There is also the <strong>Geometric Mean</strong>, which uses the <strong>n-th root of the product</strong> of the observations:</p>
<div class="arithmatex">\[
    \bar{x}_{\text{Geom}} = \left(\Pi x_{i} \right)^{\frac{1}{n}}
\]</div>
<p>The two are best applied in the following situations:</p>
<ul>
<li><strong>Change Linearly</strong>: Arithmetic average (Think Arithmetic Series)</li>
<li><strong>Change Exponentially</strong>: Geometric Average (Think Geometric Series)</li>
</ul>
</div>
<p>One problem with the Mean is that it is <strong>sensitive to outliers</strong>. An extremely large outlier could cause the mean to be well above or below the rest of the observations, reducing its reliability.</p>
<p>Thus, the <strong>Median</strong> is considered as well, which is the <strong>midpoint of the population</strong>, where <strong>at least half the observations</strong> is at least above or below the value:</p>
<div class="arithmatex">\[
\begin{array}{|c|c|}
\hline
    \text{Population Median} &amp;
    \text{Sample Median} \\
\hline
    \displaystyle{P(X \le m) \ge \frac{1}{2}} &amp; \displaystyle{m_{\text{Odd}} = x_{\frac{n+1}{2}}} \\
    \displaystyle{P(X \ge m) \le \frac{1}{2}} &amp; \displaystyle{m_{\text{Even}} = \frac{x_{\frac{n}{2}} + x_{\frac{n}{2} + 1}}{2}} \\
\hline
\end{array}
\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The formula for the sample median assumes that the sample is <strong>sorted in ascending order</strong>.</p>
</div>
<p>The last common measure is the <strong>Mode</strong> of the population, which is the <strong>most common value</strong> in the distribution or sample.</p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>The term mode came from "Maximum Ordinate Frequency".</p>
</div>
<!-- Obtained from Ledidi -->
<p><img alt="CENTRAL_TENDENCY" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/CENTRAL_TENDENCY.png" /></p>
<h3 id="dispersion"><strong>Dispersion</strong><a class="headerlink" href="#dispersion" title="Permanent link">&para;</a></h3>
<p>The next set of parameters and statistics are concerned with <strong>Dispersion</strong>, which is a measure of how <strong>stretched or squeezed</strong> a distribution is.</p>
<!-- Obtained from Six Sigma -->
<p><img alt="SIX_SIGMA" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/DISPERSION.png" /></p>
<p>The most common measure is the <strong>Variance</strong>, which measures the <strong>spread</strong> of values about the mean:</p>
<div class="arithmatex">\[
\begin{array}{|c|c|}
\hline
    \text{Population Variance} &amp;
    \text{Sample Variance} \\
\hline
    \displaystyle{\sigma^{2} = \frac{\sum (x_{i} - \mu)^{2}}{N}} &amp;
    \displaystyle{s^{2} = \frac{\sum (x_{i} - \bar{x})^{2}}{n-1}} \\
\hline
\end{array}
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The variance has the following key properties which makes it desirable:</p>
<ul>
<li>Differences are squared thus <strong>outliers are emphasised</strong>, giving <strong>better sense</strong> of spread</li>
<li>Consequently, the spread is <strong>positive only</strong>, ensuring <strong>no offsetting</strong> effects</li>
<li><strong>Other Mathematical properties</strong> which makes it <strong>easier to manipulate</strong> (EG. Variance of sum of independent variables is the sum of the individual variances)</li>
</ul>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The variance is essentially the mean of the squared deviations from the mean. Thus, it is sometimes also referred to as the <strong>Mean Squared</strong>.</p>
<p>However, it is not truly the "mean" as the division is by <span class="arithmatex">\(n-1\)</span> rather than <span class="arithmatex">\(n\)</span>. This is a result of <strong>Bessel's Correction</strong>, which ensures that the resulting sample variance is an <strong>Unbiased Estimator</strong> of the population variance. It is not necessary to know the proof for the purposes of this exam.</p>
<p>Additionally, Bessel's Correction <strong>only affects the sample variance</strong> - the resulting sample SD is a BIASED estimator.</p>
</div>
<p>However, the units of the variance are squared, which makes it hard to <strong>hard to interpret</strong>. Thus, the <strong>Standard Deviation</strong> (SD) which is the square root of the variance is also considered:</p>
<div class="arithmatex">\[
\begin{array}{|c|c|}
\hline
    \text{Population Standard Deviation} &amp;
    \text{Sample Standard Deviation} \\
\hline
    \displaystyle{\sigma = \sqrt{\frac{\sum (x_{i} - \mu)^{2}}{N}}} &amp;
    \displaystyle{s = \sqrt{\frac{\sum (x_{i} - \bar{x})}{n-1}}} \\
\hline
\end{array}
\]</div>
<p>Similarly, the SD may <strong>not be meaningful</strong> to be used to <strong>compare</strong> the dispersion across different groups due to <strong>different units and scale</strong>. Thus, the <strong>Coefficient of Variation</strong> (CV) is measured, which is the <strong>ratio of the SD relative to the mean</strong>:</p>
<div class="arithmatex">\[
\begin{array}{|c|c|}
\hline
    \text{Population Coefficient of Variation} &amp;
    \text{Sample Coefficient of Variation} \\
\hline
    \displaystyle{\text{CV} = \frac{\sigma}{\mu}} &amp;
    \displaystyle{\hat{\text{CV}} = \frac{s}{\bar{x}}} \\
\hline
\end{array}
\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Naturally, the CV is not useful in situations where the <strong>Mean is close to 0</strong>, as the CV will <strong>approach infinity</strong>.</p>
</div>
<p>The last common measure is the <strong>Interquartile Range</strong> (IQR). It is the <strong>difference</strong> between the 75<sup>th</sup> and 25<sup>th</sup> Percentiles:</p>
<div class="arithmatex">\[
    \text{IQR} = P_{75} - P_{25} = Q_{3} - Q_{1}
\]</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>The 25<sup>th</sup>, 50<sup>th</sup> and 75<sup>th</sup> Percentiles are specially known as <strong>Quartiles</strong>, hence the naming. They are denoted by <span class="arithmatex">\(Q_{i}\)</span>.</p>
</div>
<p>The IQR is most often used to <strong>identify outliers</strong>. It is generally accepted that fall outside of the "fences" are considered outliers:</p>
<div class="arithmatex">\[
\begin{aligned}
    \text{Lower Fence} &amp;= Q_{1} - 1.5 \cdot \text{IQR} \\
    \text{Upper Fence} &amp;= Q_{3} + 1.5 \cdot \text{IQR}
\end{aligned}
\]</div>
<p>The IQR and the "fences" can be illustrated using a <strong>Box-plot</strong>:</p>
<!-- Obtained from Scribbor -->
<p><img alt="BOXPLOT" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/BOXPLOT.png" /></p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>There is actually <strong>no formal definition for what is considered an outlier</strong> in statistics. There is also <strong>no strong mathematical basis</strong> for why the fence was set at that level; it was a reasonable range that became popularized.</p>
</div>
<h3 id="bivariate"><strong>Bivariate</strong><a class="headerlink" href="#bivariate" title="Permanent link">&para;</a></h3>
<p><strong>Covariance</strong> is a measure of the <strong>linear relationship</strong> between two variables:</p>
<ul>
<li><strong>Positive Covariance</strong> - Variables move in the <strong>same direction</strong></li>
<li><strong>Negative Covariance</strong> - Variables move in <strong>opposite directions</strong></li>
</ul>
<div class="arithmatex">\[
\begin{array}{|c|c|}
\hline
    \text{Population Covariance} &amp;
    \text{Sample Covariance} \\
\hline
    \displaystyle{\sigma_{x, y} = \text{Cov}(X, Y) = \mu_{x, y} - \mu_{x} \cdot \mu_{y}} &amp;
    \displaystyle{\hat{\sigma}_{x, y} = \frac{1}{n-1} \sum (x_{i} - \bar{x}) \cdot (y_{i} - \bar{y})} \\
\hline
\end{array}
\]</div>
<p>However, there are two issues with Covariance:</p>
<ol>
<li>Units are <strong>unintuitive</strong> (similar to variance)</li>
<li><strong>No benchmark</strong> as to what constitutes a strong/weak relationship</li>
</ol>
<p>Thus, the <strong>Correlation</strong> is an adjusted measure of the relationship <strong>between -1 and 1</strong>, which accounts for the above issues:</p>
<div class="arithmatex">\[
\begin{array}{|c|c|}
\hline
    \text{Population Correlation} &amp;
    \text{Sample Correlation} \\
\hline
    \displaystyle{\rho = \text{Corr}(X, Y) = \frac{\sigma_{x, y}}{\sigma_{x} \cdot \sigma_{y}}} &amp;
    \displaystyle{r = \frac{\sum (x_{i} - \bar{x})(y_{i} - \bar{y})}{\sum(x_{i} - \bar{x}) \cdot \sum(y_{i} - \bar{y})}} \\
\hline
\end{array}
\]</div>
<p>The relationship between the variables can also be visualized using a Scatterplot of the data:</p>
<!-- Obtained from Latest Quality -->
<p><img alt="SCATTEPLOT" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/SCATTERPLOT.png" /></p>
<h3 id="bias-variance"><strong>Bias Variance</strong><a class="headerlink" href="#bias-variance" title="Permanent link">&para;</a></h3>
<p>The <strong>Error</strong> of an estimate is the difference between the Sample Estimate and the Population Parameter:</p>
<div class="arithmatex">\[
    \varepsilon = \hat{\theta} - \theta
\]</div>
<p>The Bias of an estimator is the <strong>expected value</strong> of the error:</p>
<div class="arithmatex">\[
    B(\hat{\theta}) = E(\hat{\theta} - \theta)
\]</div>
<p>An estimator is <strong>unbiased if and only if the Bias is 0</strong>. It can be understood that - <strong>on average</strong>, the estimator produces an <strong>estimate that is equal to the true value</strong>; individual estimates may still have errors.</p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Biasness is a property of the <strong>Estimator, not the estimate</strong>. Thus, the term “Biased Estimate” should not be used in a statistical context.</p>
</div>
<p>The Variance of an Estimator (<strong>Sampling Variance</strong>) is the spread of estimates about its mean:</p>
<div class="arithmatex">\[
    \mathrm{Var}(\hat{\theta}) = E[\hat{\theta} - E(\hat{\theta})]^{2}
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Standard Deviation of the Estimator (<strong>Sampling Deviation</strong>) is the square root of the sampling variance. It is also known as the <strong>Standard Error</strong> of the estimator.</p>
</div>
<p>A similar measure is known as the <strong>Mean Squared Error</strong> (MSE), which is the spread of estimates <strong>about the Population Parameter</strong>. It can be shown to be the <strong>combination of the Bias and Variance</strong> of the estimator:</p>
<div class="arithmatex">\[
\begin{aligned}
    \text{MSE}(\hat{\theta})
    &amp;= E[\hat{\theta} - \theta]^{2} \\
    &amp;= \mathrm{Var}(\hat{\theta} - \theta) + [E(\hat{\theta} - \theta)]^{2} \\
    &amp;= \mathrm{Var}(\hat{\theta}) + \text{Bias}^{2}(\hat{\theta})
\end{aligned}
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The proof for the above relationship is based on the relationship between the Mean and Variance:</p>
<div class="arithmatex">\[
\begin{aligned}
    \mathrm{Var}(X) &amp;= E(X^{2}) - [E(X)]^{2} \\
    X &amp;= \theta - \hat{\theta} \\
    \\
    \therefore \mathrm{Var} &amp;= \text{MSE} - \text{Bias}^{2} \\
    \therefore \text{MSE} &amp;= \mathrm{Var} + \text{Bias}^{2}
\end{aligned}
\]</div>
</div>
<p>Variance and MSE are <strong>both measuring the dispersion</strong> of the estimator. The key difference is the reference point:</p>
<ul>
<li><strong>Variance</strong>: Relative to the average of the estimator</li>
<li><strong>MSE</strong>: Relative to the population parameter</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>As seen in the above formula, MSE is not just about the spread of the estimates. An estimator which produces <strong>clustered estimates that are far from the true value</strong> has low variance, but <strong>high bias and hence high MSE</strong>.</p>
<p>To have a low MSE, the estimator must have both a low bias AND low variance:</p>
<p><!-- Obtained from Scott Fortman Roe -->
<img alt="BIAS_VARIANCE" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/BIAS_VARIANCE.png" /></p>
</div>
<p>Generally speaking, <strong>estimators with lower MSE are preferred</strong>. Note that this could also mean using a slightly biased estimator with low variance compared to using a unbiased estimator with high variance. There is <strong>no clear rule given the two dimensional nature of MSE</strong>.</p>
<h3 id="degrees-of-freedom"><strong>Degrees of Freedom</strong><a class="headerlink" href="#degrees-of-freedom" title="Permanent link">&para;</a></h3>
<p>Degrees of freedom (<span class="arithmatex">\(\nu\)</span>) refer to the <strong>number of independent pieces of data that are free to vary</strong> in the calculation of a statistic <strong>without violating any of the constraints</strong> of said statistic.</p>
<p>Number of independent pieces of data typically refers to the number of observations used; <strong>sample size</strong>. It is then usually <strong>reduced by the number of constraints</strong> imposed during the calculation:</p>
<div class="arithmatex">\[
    \nu = n - \text{Constraints}
\]</div>
<p>To illustrate, consider the two most basic statistics:</p>
<p><center></p>
<table>
<thead>
<tr>
<th align="center"><strong>Sample Mean</strong></th>
<th align="center"><strong>Sample Variance</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">No constraints</td>
<td align="center">Constrained by the sample mean</td>
</tr>
<tr>
<td align="center"><span class="arithmatex">\(n\)</span> degrees of freedom</td>
<td align="center"><span class="arithmatex">\(n-1\)</span> degrees of freedom</td>
</tr>
</tbody>
</table>
<p></center></p>
<p>When computing the variance, the sample mean is <strong>already a fixed quantity</strong>. The average of the observations used in the sample <strong>MUST be equal to the sample mean</strong> (constraints). Thus, only <span class="arithmatex">\(n-1\)</span> points are able to freely vary, the last observation MUST force the average to be the sample mean; not free to vary.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>This can be better understood as one degree of freedom being "used up" to determine the sample mean, thus all subsequent calculations <strong>involving the sample mean</strong> has one less degree of freedom.</p>
</div>
<h2 id="sampling-distribution"><strong>Sampling Distribution</strong><a class="headerlink" href="#sampling-distribution" title="Permanent link">&para;</a></h2>
<p>Whenever a sample is drawn from a population and a statistic is calculated, it is known as a <strong>Point Estimate</strong>.</p>
<p>Due to measurement errors, a different sample would be drawn each time, thus leading to a <strong>different point estimate</strong>. If this process were to be repeated a large number times, the <strong>probability distribution</strong> of the resulting point estimates is known as the <strong>Sampling Distribution</strong> of the statistic.</p>
<p>There is <strong>no rule</strong> surrounding the sampling distribution - it depends on the distribution of the population, statistic being measured, sampling method etc.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>It may be hard to understand initially, but the distribution of sample statistics is <strong>itself a population</strong>. It is <strong>different from the underlying population</strong> that is being sampled.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A well-known sampling distribution is that of the <strong>Sample Mean</strong>. Given a large enough sample size, it can be shown that the Sample Mean is approximately <strong>normally distributed</strong>.</p>
<p>This is a result of the <strong>Central Limit Theorem</strong>. The technical proof is out of scope for the purposes of this exam.</p>
</div>
<!-- Obtained from Claus Wike -->
<p><img alt="SAMPLING_DISTRIBUTION" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/SAMPLING_DISTRIBUTION.png" /></p>
<p>Many commonly studied sampling distributions can be shown to be <strong>normally distributed</strong>. However, it can also be <strong>transformed to a variety of other distributions</strong> that are commonly used in Statistical Theory.</p>
<h3 id="standard-normal-distribution"><strong>Standard Normal Distribution</strong><a class="headerlink" href="#standard-normal-distribution" title="Permanent link">&para;</a></h3>
<p>Due to the shifting and scaling properties of the normal distribution, any normal distribution can be converted to a <strong>Standard Normal Distribution</strong> via a process known as <strong>Standardization</strong>:</p>
<div class="arithmatex">\[
    Z = \frac{\hat{\theta} - E(\hat{\theta})}{\text{SE}(\hat{\theta})}   
\]</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>It is recommended to Standardize for two reasons:</p>
<ol>
<li>It removes scale from the picture, <strong>facilitating comparison</strong> across different distributions</li>
<li>Probabilities for the standard normal are well documented, <strong>no need to compute</strong> for each unique normal distribution </li>
</ol>
</div>
<h3 id="t-distribution"><strong>t-Distribution</strong><a class="headerlink" href="#t-distribution" title="Permanent link">&para;</a></h3>
<p>The SE of the sampling distribution is typically a <strong>function of the underlying</strong> population standard deviation. However, in many cases, it is an <strong>unknown value</strong>. Thus, it can be <strong>estimated</strong> using the sample standard deviation instead:</p>
<div class="arithmatex">\[
\begin{aligned}
    \text{SE}(\hat{\theta}) &amp;\approx \widehat{\text{SE}}(\hat{\theta}) \\
    f(\sigma_{\theta}) &amp;\approx f(\hat{\sigma}_{\theta})   
\end{aligned}
\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The sample SD is not estimating the SE, it is the <strong>function of the sample SD</strong> that is the estimating the SE.</p>
<p>For example, consider the distribution of the <strong>Sample Mean</strong>, which through CLT can be shown to be <strong>normally distributed</strong>:</p>
<div class="arithmatex">\[
\begin{aligned}
    \text{Var}(\bar{{x}})
    &amp;= \text{Var} \left(\frac{\sum x_{i}}{n} \right) \\
    &amp;= \frac{1}{n^{2}} \cdot \text{Var} \left(\sum x_{i} \right) \\
    &amp;= \frac{1}{n^{2}} \cdot n \cdot \sigma^{2}_{x} \\
    &amp;= \frac{\sigma^{2}_{x}}{n} \\
    \\
    \text{SE}(\bar{x})
    &amp;= \text{SD}(\bar{x}) \\
    &amp;= \sqrt{Var(\bar{x})} \\
    &amp;= \frac{\sigma_{x}}{\sqrt{n}} \\
    \\
    \therefore \widehat{\text{SE}} &amp;= \frac{s_{x}}{\sqrt{n}} 
\end{aligned}
\]</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>There are now four layers to the estimation:</p>
<ol>
<li><strong>Population</strong> - Standard Deviation <span class="arithmatex">\(\sigma_{\theta}\)</span></li>
<li><strong>Estimate of the Population</strong> - Sample Standard Deviation <span class="arithmatex">\(\hat{\sigma}_{\theta}\)</span></li>
<li><strong>Sampling Distribution</strong> - Standard Error <span class="arithmatex">\(\sigma_{\hat{\theta}}\)</span></li>
<li><strong>Estimate of the Sampling Distribution</strong> - Estimator of the Standard Error <span class="arithmatex">\(\hat{\sigma}_{\hat{\theta}}\)</span></li>
</ol>
<p>The key takeaway is that we will <strong>never know true sampling distribution</strong>, we only have an estimate of it which <strong>changes from sample to sample</strong>. </p>
</div>
<p>If the standard error was estimated this way, then the resulting distribution now follows a <strong>t-distribution</strong>. It is essentially a standard normal distribution with a <strong>lower peak and fatter tails</strong>, which accounts for the <strong>increased uncertainty</strong> from using an estimate instead of the actual value in specifying the distribution.</p>
<p>The t-distribution has only one parameter - the <strong>degrees of freedom</strong> of the statistic of the sampling distribution. As the degrees of freedom (sample size) increases, the t-distribution <strong>tends towards the standard normal distribution</strong>:</p>
<!-- Obtained from Scribbr -->
<p><img alt="T_Distribution" class="center" src="Assets/0.%20Review%20of%20Statistical%20Theory.md/T_DISTRIBUTION.png" /></p>
<p>The process of converting a normal distributed quantity into a t-distributed one is known as <strong>Studentization</strong>:</p>
<div class="arithmatex">\[
\begin{aligned}
    t_{n-1}
    &amp;= \frac{\hat{\theta} - E(\hat{\theta})}{\hat{\text{SE}}(\hat{\theta})} \\
    &amp;= \frac{\hat{\theta} - E(\hat{\theta})}{\hat{\sigma}_{\theta}}
\end{aligned}
\]</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Standardization is known as such because it is converting the distribution to a <strong>Standard</strong> normal distribution.</p>
<p>Studentization is known as such because the t-distribution is more formally known as the <strong>Student's</strong> t-distribution.</p>
</div>
<h3 id="chi-squared-distribution"><strong>Chi-Squared Distribution</strong><a class="headerlink" href="#chi-squared-distribution" title="Permanent link">&para;</a></h3>
<p>A well-known sampling distribution is the <strong>Chi-Square Distribution</strong>. It is equivalent to a <strong>Squared Standard Normal Distribution</strong>:</p>
<div class="arithmatex">\[
    \chi^{2}_{1} = Z^{2}
\]</div>
<p>Similar to the t-distribution, it only has one parameter - the <strong>degrees of freedom</strong> of the underlying statistic. The sum of <span class="arithmatex">\(n\)</span> <strong>independent</strong> squared normal variables results in a Chi-Squared Distribution with <strong><span class="arithmatex">\(n\)</span> degrees of freedom</strong>:</p>
<div class="arithmatex">\[
    \chi^{2}_{n} = Z^{2}_{1} + Z^{2}_{2} + Z^{2}_{3} + \dots + Z^{2}_{n}
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As the degrees of freedom increases (as more standard normals are summed), the chi-square distribution will tend towards a normal distribution due to the <strong>Central Limit Theorem</strong>.</p>
</div>
<p>The shape of the chi-squared distribution is quite different compared to the Standard Normal, reflecting two key properties:</p>
<ol>
<li>Squared variables are always <strong>non-negative</strong></li>
<li>Square of 0 (standard normal peak) is still 0, thus the <strong>peak of the chi-square is still 0</strong>, which <strong>declines thereafter</strong></li>
<li>Squared variables result in larger variance, thus has a <strong>right skew</strong></li>
</ol>
<!-- Obtained from Live Boost -->
<p><img alt="CHI_SQUARED" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/CHI_SQUARED.png" /></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Very few real world phenomena follow a chi-squared distribution; it is mainly used for hypothesis testing.</p>
</div>
<h4 id="sample-variance"><strong>Sample Variance</strong><a class="headerlink" href="#sample-variance" title="Permanent link">&para;</a></h4>
<p>By definition, a chi-square variable can be written as:</p>
<div class="arithmatex">\[
\begin{aligned}
    \chi^{2}_{n}
    &amp;= \sum^{n}_{1} Z^{2} \\
    &amp;= \sum^{n}_{1} \left(\frac{\theta_{i} - \mu}{\sigma} \right)^{2}    
\end{aligned}
\]</div>
<p>It can be shown via <strong>Cochran's Theorem</strong> (out of scope for this exam) that the following is true:</p>
<div class="arithmatex">\[
    \sum^{n}_{1} (\theta_{i} - \bar{\theta}) \sim \sigma^{2} \cdot \chi^{2}_{\nu}   
\]</div>
<p>Thus, the sample variance (following Bessel's Correction) can be shown to be have a <strong>scaled chi-square distribution</strong>:</p>
<div class="arithmatex">\[
\begin{aligned}
    \sum^{n}_{1} (\theta_{i} - \bar{\theta}) &amp;\sim \sigma^{2} \cdot \chi^{2}_{\nu} \\
    \frac{\sum^{n}_{1} (\theta_{i} - \bar{\theta})}{n-1} &amp;\sim \frac{\sigma^{2} \cdot \chi^{2}_{\nu}}{\nu} \\
    \frac{s^{2}}{\sigma^{2}} &amp;\sim \frac{\chi^{2}_{\nu}}{\nu}
\end{aligned}
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A scaled chi-square distribution refers to a one that has been <strong>divided by its degrees of freedom</strong>; average of the squared normals.</p>
</div>
<h4 id="reformulated-t"><strong>Reformulated t</strong><a class="headerlink" href="#reformulated-t" title="Permanent link">&para;</a></h4>
<p>Using the above, it is possible to express the t-distribution in terms of a chi-squared one:</p>
<div class="arithmatex">\[
\begin{aligned}
    t_{\nu}
    &amp;= \frac{\theta - E(\hat{\theta})}{s} \\
    &amp;= \frac{\theta - E(\hat{\theta})}{\sqrt{\mathrm{Var}(\hat{\theta})}} \cdot \sqrt{\frac{\mathrm{Var}(\hat{\theta})}{s^{2}}} \\
    &amp;= \frac{\theta - E(\hat{\theta})}{\sqrt{\mathrm{Var}(\hat{\theta})}} \div \sqrt{\frac{s^{2}}{\mathrm{Var}(\hat{\theta})}} \\
    &amp;= \frac{Z}{\sqrt{\frac{\chi^{2}_{\nu}}{\nu}}}
\end{aligned}
\]</div>
<p>Thus, a t-distribution is the ratio of standard normal variable to the squareroot of a chi-squared distribution divided by its degrees of freedom.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>As the <strong>degrees of freedom tends to infinity</strong>, the scaled chi-squared distribution will tend to 1. This is why the t-distribution tends towards a standard normal distribution:</p>
<div class="arithmatex">\[
\begin{aligned}
    \lim_{\nu \to \infty} \frac{\chi_{\nu}}{\nu} \to 1 \\
    \therefore \lim_{n \to \infty} t_{\nu} \to Z
\end{aligned}
\]</div>
<p>The limit of the scaled chi-square variable is a result of <strong>Slutsky's theorem</strong>, which is out of scope for the purposes of this exam.</p>
</div>
<h4 id="goodness-of-fit"><strong>Goodness of fit</strong><a class="headerlink" href="#goodness-of-fit" title="Permanent link">&para;</a></h4>
<p>A Chi-Square test is used to determine whether the population <strong>follows a specified distribution</strong>; how good the population fits the distribution. It can only be used for <strong>Discrete Variables</strong>.</p>
<p>Discrete Variables generally follow a <strong>Multinomial distribution</strong> (out of scope for this exam), which is a generalization of the Binomial distribution:</p>
<ul>
<li><strong>Bi-Nomial</strong>: Two outcomes (EG. Heads or Tails)</li>
<li><strong>Multi-Nomial</strong>: Multiple Outcomes (EG. Roll of a six sided die)</li>
</ul>
<p>Multinomial distributions can typically be expressed in the form of a <strong>Contingency Table</strong>, which contains the <strong>count/frequency</strong> of each observation:</p>
<!-- Obtained from Research Gate -->
<p><img alt="CONTINGENCY_TABLE" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/CONTINGENCY_TABLE.png" /></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The distribution of majors among for each level of expertise.</p>
</div>
<p>The Chi-Square test is to determine whether the <strong>Observed distribution</strong> (<span class="arithmatex">\(O\)</span>) follows the <strong>Expected Distribution</strong> (<span class="arithmatex">\(E\)</span>):</p>
<!-- Obtained from JMP -->
<p><img alt="GOODNESS_OF_FIT" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/GOODNESS_OF_FIT.png" /></p>
<p>Consider a variable with <span class="arithmatex">\(k\)</span> possible outcomes. The resulting Chi-Squared test-statistic is:</p>
<div class="arithmatex">\[
    \chi^{2}_{\text{test}} = \frac{\sum^{k}_{i} (O_{i} - E_{i})^{2}}{E_{i}}
\]</div>
<p>The above can be shown to follow a Chi-Square distribution:</p>
<div class="arithmatex">\[
\begin{aligned}
    \chi^{2}_{\text{test}}
    &amp;= \frac{\sum^{k}_{i} (O_{i} - E_{i})^{2}}{E_{i}} \\
    &amp;= \left(\frac{\sum^{k}_{i} (O_{i} - E_{i})}{\sqrt{E_{i}}} \right)^{2} \\
    \\
    \frac{(O_{i} - E_{i})}{\sqrt{E_{i}}} &amp;\sim Z \\
    \\
    \therefore \chi^{2}_{\text{test}} &amp;\sim \chi^{2}_{k-1}
\end{aligned}
\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Despite being the sum of <span class="arithmatex">\(k\)</span> standard normals, the test-statistic loses one degree of freedom since there is a constraint the total number of observations is fixed.</p>
<p>If we know the frequencies for <span class="arithmatex">\(k-1\)</span> categories, then the last observation MUST be a certain number such that the total number of observations tally.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The expression within the statistic is standard normal for two reasons:</p>
<ol>
<li>For large sample sizes, due to CLT, the observations follow a <strong>normal distribution</strong></li>
<li>For large sample sizes, the variance is <strong>approximately equal to the mean</strong></li>
<li>Thus, the expression is simply a result of <strong>standardization of this distribution</strong></li>
</ol>
<p>The properties of a multinomial distribution are extremely similar to a binomial one:</p>
<ul>
<li>Expectation of <em>each</em> category = <span class="arithmatex">\(n \cdot p_{i}\)</span></li>
<li>Variance of <em>each</em> category = <span class="arithmatex">\(n \cdot p_{i} \cdot (1 - p_{i})\)</span></li>
</ul>
<p>When <span class="arithmatex">\(n\)</span> is large, <span class="arithmatex">\((1 - p_{i}) \approx 1\)</span> thus the variance is approximately equal to the mean.</p>
</div>
<p>For non-categorical data, an alternative (though less rigorous) method of determining goodness of fit is using a <strong>Quantile-Quantile</strong> plot (Q-Q Plot):</p>
<ol>
<li>Quantiles of the Sample and Theoretical distribution are plotted against each other</li>
<li>A reference identity line of <span class="arithmatex">\(y=x\)</span> is drawn</li>
<li>If the quantiles lie mostly on the line (Sample Quantile = Theoretical Quantile), then the sample can be concluded to follow the theoretical distribution </li>
</ol>
<!-- Obtained from Analyst Prep -->
<p><img alt="QQ_PLOT" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/QQ_PLOT.png" /></p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Quantiles are "cut-points" in a distribution which <strong>equally splits</strong> the resulting intervals. For instance, the two statistics covered earlier are examples of commonly used Quantiles:</p>
<ul>
<li><strong>Percentile</strong>: Splits 100 ways, each with 1% density</li>
<li><strong>Quartile</strong>: Splits 4 ways, each with 25% density</li>
</ul>
<p>Do not confuse them with Quartiles!</p>
</div>
<h3 id="f-distribution"><strong>F-Distribution</strong><a class="headerlink" href="#f-distribution" title="Permanent link">&para;</a></h3>
<p>The <strong>ratio</strong> of two <strong>independent</strong> scaled chi-square distributions results in a <strong>F-distribution</strong> with BOTH the degrees of freedom as parameters:</p>
<div class="arithmatex">\[
    F_{m,n} = \frac{\frac{\chi_{m}}{m}}{\frac{\chi_{n}}{n}}
\]</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>The two degrees of freedom can be informally referred to as:</p>
<ul>
<li><strong>Numerator</strong> degree of freedom (ndf)</li>
<li><strong>Denominator</strong> degree of freedom (ddf)</li>
</ul>
</div>
<p>The F-distribution can be reformulated in terms of the previous two distributions:</p>
<div class="arithmatex">\[
\begin{aligned}
    (t_{\nu})^{2}
    &amp;= \left(\frac{Z}{\sqrt{\frac{\chi^{2}_{\nu}}{\nu}}} \right)^{2} \\
    &amp;= \frac{Z^{2}}{\frac{\chi^{2}_{\nu}}{\nu}} \\
    &amp;= \frac{\frac{\chi^{2}_{1}}{1}}{\frac{\chi^{2}_{\nu}}{\nu}} \\
    &amp;= F_{1,\nu} \\
    \therefore t^{2}_{\nu} &amp;\sim F_{1, \nu} \\
    \therefore t^{-2}_{\nu} &amp;\sim F_{\nu, 1} \\
    \\
    \lim_{\nu \to \infty} \frac{\chi_{\nu}}{\nu} &amp;\to 1 \\
    \lim_{\nu \to \infty} F_{m, \nu} &amp;\to \frac{\chi_{\nu}}{\nu} \\
    \therefore F_{m, \infty} &amp;\sim \frac{\chi_{\nu}}{\nu}
\end{aligned}
\]</div>
<h4 id="equality-of-variance"><strong>Equality of Variance</strong><a class="headerlink" href="#equality-of-variance" title="Permanent link">&para;</a></h4>
<p>An F-test is typically used to compare if the Variance of two populations are equal:</p>
<ul>
<li><span class="arithmatex">\(H_{0}: \sigma^{2}_{A} = \sigma^{2}_{B}\)</span></li>
<li><span class="arithmatex">\(H_{1}: \sigma^{2}_{A} \ne \sigma^{2}_{B}\)</span></li>
</ul>
<p>The corresponding <strong>F-statistic</strong> is the ratio of the two sample variances being tested:</p>
<div class="arithmatex">\[
    F_{\text{Statistic}} = \frac{s^{2}_{A}}{s^{2}_{B}}
\]</div>
<p>Under the null, the statistic can be shown to be following a F-distribution:</p>
<div class="arithmatex">\[
\begin{aligned}
    F_{\text{Statistic}}
    &amp;= \frac{\frac{\chi_{n_{A}-1}}{n_{A}-1}}{\frac{\chi_{n_{B}-1}}{n_{B}-1}} \\
    &amp;= \frac{\frac{s^{2}_{A}}{\sigma^{2}_{A}}}{\frac{s^{2}_{B}}{\sigma^{2}_{B}}} \\
    &amp;= \frac{s^{2}_{A}}{\sigma^{2}_{A}} \cdot \frac{\sigma^{2}_{B}}{s^{2}_{B}} \\
    &amp;= \frac{s^{2}_{A}}{s^{2}_{B}} \cdot \frac{\sigma^{2}_{B}}{\sigma^{2}_{A}} \\
    &amp;= \frac{s^{2}_{A}}{s^{2}_{B}} \\
    \\
    F_{\text{test}} &amp;\sim F_{n_{A}-1, n_{B}-1}
\end{aligned}
\]</div>
<p>Thus, if the two variances are not equal, the statistic would not follow a F-distribution and hence result in extreme values (relative to the F-distribution).</p>
<h4 id="anova"><strong>ANOVA</strong><a class="headerlink" href="#anova" title="Permanent link">&para;</a></h4>
<p>Although F-tests compare variances, they can be used to make inferences about the mean as well. This is done through a process known as <strong>Analysis of Variance</strong> (ANOVA).</p>
<p>Under ANOVA, the F-test can be restated as:</p>
<div class="arithmatex">\[
\begin{aligned}
    F_{\text{Statistic}}
    &amp;= \frac{\text{Variance Between Groups}}{\text{Variance Within Groups}} \\
    &amp;= \frac{\text{Explained Variance}}{\text{Unexplained Variance}}
\end{aligned}
\]</div>
<p>By the <strong>Law of Total Variance</strong>, variance can be decomposed into two components:</p>
<div class="arithmatex">\[
\begin{aligned}
    \text{Var(X)}
    &amp;= E_{Y}[\text{Var}(X \mid Y)] + \text{Var}_{Y}[E_{Y}(X \mid Y)] \\
    &amp;= \text{Variance Within Groups} + \text{Variance Between Groups} \\
    &amp;= \text{Unexplained Variance} + \text{Explained Variance}
\end{aligned}
\]</div>
<ul>
<li><strong>Variance Within Groups</strong>: Variance within the distribution of <span class="arithmatex">\(X \mid Y\)</span> for a given <span class="arithmatex">\(Y\)</span> (<strong>Noise</strong>)</li>
<li><strong>Variance Between Groups</strong>: Variance between the means of <span class="arithmatex">\(X \mid Y\)</span> for different <span class="arithmatex">\(Y\)</span> (<strong>Signal</strong>)</li>
</ul>
<p>The key is to identify if any differences between groups is <strong>due to a true difference between groups, or if it is due to random variation</strong>. ANOVA uses the variance within groups as a benchmark - if the variance between groups is significantly larger, then it is likely that there is a <strong>true difference</strong> in the two groups.</p>
<h2 id="statistical-inference"><strong>Statistical Inference</strong><a class="headerlink" href="#statistical-inference" title="Permanent link">&para;</a></h2>
<h3 id="confidence-interval"><strong>Confidence Interval</strong><a class="headerlink" href="#confidence-interval" title="Permanent link">&para;</a></h3>
<p>Given that there is only one true value for the population parameter and a whole distribution of estimators, it is unlikely that a point estimate will be equal to the population parameter. Thus, instead of a single point estimate, a range is used, known as a <strong>Confidence Interval</strong>.</p>
<p>The interval is made at a chosen <strong>Confidence Level</strong> which represents the <strong>proportion of confidence intervals that will contain the true value</strong>. In other words, if a large number of confidence intervals constructed in the <strong>same manner</strong> were to be made, <span class="arithmatex">\((1-\alpha)%\)</span> of them would contain the true value.</p>
<div class="arithmatex">\[
    P(\text{Lower Bound} &lt; \theta &lt; \text{Upper Bound}) = 1 - \alpha
\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>A common misinterpretation is that there is a <span class="arithmatex">\((1-\alpha)%\)</span> probability that the population parameter lies within a specific interval. This is WRONG. Once an interval is determined, the population parameter either lies within or outside that interval; it is <strong>not a probability</strong>.</p>
<p>Thus, the confidence level is measuring the <strong>reliability of the estimation procedure</strong>, not a specific estimate.</p>
</div>
<!-- Obtained from Clausewike -->
<p><img alt="CONFIDENCE_INTERVAL_PROPORTION" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/CONFIDENCE_INTERVAL_PROPORTION.png" /></p>
<p>The bounds of the confidence interval are derived <strong>based on the sampling distribution</strong>:</p>
<ol>
<li>Using the sampling distribution, find a range of values that cover <span class="arithmatex">\((1-\alpha)%\)</span> of density</li>
<li>Re-express the range of values in terms of the true parameter</li>
</ol>
<p>Consider the sampling distribution of the sample mean:</p>
<div class="arithmatex">\[
\begin{aligned}
    \bar{x} \sim N \left(\mu, \frac{\sigma}{\sqrt{n}} \right) \\
    \\
    P(p_{0 + \frac{1+\alpha}{2}} \le \bar{x} \le p_{100 - \frac{1+\alpha}{2}}) &amp;= (1-\alpha) \\
    P \left(Z_{0 + \frac{1+\alpha}{2}} \le \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}} \le Z_{100 - \frac{1+\alpha}{2}} \right) &amp;= (1-\alpha) \\
    P \left(\mu + Z_{0 + \frac{1+\alpha}{2}} \cdot \frac{\sigma}{\sqrt{n}} \le \bar{x} \le \mu + \frac{\sigma}{\sqrt{n}} \cdot Z_{100 - \frac{1+\alpha}{2}} \right) &amp;= (1-\alpha) \\
    P \left(\bar{x} + Z_{0 + \frac{1+\alpha}{2}} \cdot \frac{\sigma}{\sqrt{n}} \le \mu \le \bar{x} + Z_{100 - \frac{1+\alpha}{2}} \cdot \frac{\sigma}{\sqrt{n}} \right) &amp;= (1-\alpha) \\
    \therefore \left(\bar{x} + Z_{0 + \frac{1+\alpha}{2}} \cdot \frac{\sigma}{\sqrt{n}}, \bar{x} +  Z_{100 - \frac{1+\alpha}{2}} \cdot \frac{\sigma}{\sqrt{n}} \right) \\
    \\
    \therefore \text{CI} = \hat{\theta} \pm \text{Percentile} \cdot \text{SE}(\hat{\theta})
\end{aligned}
\]</div>
<p>The key is understanding that all else equal, each sample will yield a <strong>different confidence interval</strong> because the <strong>point estimate will be different</strong> due to inherent variability; on average <span class="arithmatex">\((1-\alpha)%\)</span> of these intervals will contain the true parameter.</p>
<!-- Obtained from Analyst Prep -->
<p><img alt="CONFIDENCE_INTERVAL" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/CONFIDENCE_INTERVAL.png" /></p>
<p>The confidence interval represents a range of likely values based on the sample, with the center being the point estimate representing the <strong>single most likely point</strong>. From another perspective, the interval provides a gauge of the uncertainty in the estimation, thus a <strong>narrower interval</strong> is generally preferred.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The confidence interval will <strong>gradually shrink to 0 as the sample size approaches the population size</strong>. Intuitively, this is because if the sample = population, then there is no more uncertainty; the resulting statistic IS the population parameter!</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The point estimate is the center of the confidence interval, reflecting that it is the <strong>single most likely</strong> value based on the sample.</p>
</div>
<h3 id="hypothesis-testing"><strong>Hypothesis Testing</strong><a class="headerlink" href="#hypothesis-testing" title="Permanent link">&para;</a></h3>
<p><strong>Hypothesis Testing</strong> is a formal method of making inferences about the population parameters based on the sample statistic. It starts with a <strong>Hypothesis</strong> which is a conjecture about the population parameters:</p>
<ul>
<li><strong>Null Hypothesis</strong> (<span class="arithmatex">\(H_{0}\)</span>) - What is currently believed to be true</li>
<li><strong>Alternative Hypothesis</strong> (<span class="arithmatex">\(H_{0}\)</span>) - What is to be proven</li>
</ul>
<p>The key idea is that it is a <strong>test of extremeness</strong> - <strong>assuming the null hypothesis is true</strong>, how likely (how extreme) was that particular sample (or more extreme) to be drawn?</p>
<ul>
<li>Sample was <strong>likely to be drawn</strong>, then it is likely that the <strong>null is true</strong> (Expected outcome)</li>
<li>Sample was <strong>unlikely to be drawn</strong> but yet it was drawn, is it due to <strong>variance</strong> or because the sampling distribution is misspecified because the <strong>null not being true</strong>? (Extreme outcome)</li>
</ul>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>A common phrase is that hypothesis testing is used to differentiate the Signal (True Misspecification) from the noise (Variance).</p>
</div>
<p>The probability of drawing the sample is formally known as the <strong>p-value</strong> (<span class="arithmatex">\(p\)</span>). The <strong>threshold</strong> for how likely a sample to be drawn is known is known as the <strong>Significance Level</strong> (<span class="arithmatex">\(\alpha\)</span>):</p>
<ul>
<li><span class="arithmatex">\(p &lt; \alpha\)</span>: Test is successful; null can be rejected</li>
<li><span class="arithmatex">\(p &gt; \alpha\)</span>: Test fails; null CANNOT be rejected</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Most textbooks commonly use either 0.05 or 0.01 as the significance level for the tests.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Rejecting the null hypothesis does NOT mean that the alternative is accepted. For instance, rejecting the null hypothesis that a large paw print came from a bear does not mean that the paw print came from big foot.</p>
<p>Thus, the two hypothesis are usually constructed such that they are <strong>complementary</strong> - such that rejecting null <strong>must necessarily mean that the alternative is true</strong>, which provides more insight:</p>
<ul>
<li><span class="arithmatex">\(H_{0}: \theta = x\)</span></li>
<li><span class="arithmatex">\(H_{1}: \theta \ne x\)</span></li>
</ul>
<p>Consequently, hypothesis testing is not able to confirm the true value of a parameter; it is only able to quantify whether there is enough statistical evidence to dispute a hypothesized value of a parameter.</p>
</div>
<p>The "tail" of a hypothesis test refers to the <strong>side of the distribution</strong> where the values are considered extreme. It is based on the Alternative Hypothesis:</p>
<ul>
<li><strong>Right Tail</strong>: <span class="arithmatex">\(H_{1}: \theta \gt x\)</span></li>
<li><strong>Left Tail</strong>: <span class="arithmatex">\(H_{1}: \theta \lt x\)</span></li>
<li><strong>Two Tail</strong>: <span class="arithmatex">\(H_{1}: \theta \ne x\)</span></li>
</ul>
<p>The key difference is that the critical region is split into two for a two-tail test, requiring the sample to be even more extreme to be reject the null:</p>
<ul>
<li><strong>One Tail</strong>: <span class="arithmatex">\(\alpha\)</span> on <strong>either</strong> side</li>
<li><strong>Two tail</strong>: <span class="arithmatex">\(\frac{\alpha}{2}\)</span> on <strong>both</strong> sides</li>
</ul>
<!-- Obtained from Medium -->
<p><img alt="TAIL_TEST" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/TAIL_TEST.png" /></p>
<h4 id="sources-of-error"><strong>Sources of Error</strong><a class="headerlink" href="#sources-of-error" title="Permanent link">&para;</a></h4>
<p>Given the probabilistic nature of hypothesis testing, there are bound to be errors. In particular, there are two types:</p>
<ul>
<li><strong>Type I Error</strong> (<span class="arithmatex">\(\alpha\)</span>): False Positive (Rejecting the null when it is true)</li>
<li><strong>Type II Error</strong> (<span class="arithmatex">\(\beta\)</span>): False Negative (Not rejecting the null when it is false)</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>A real world example of hypothesis testing is in court. Generally speaking, the <strong>defendant is innocent until proven guilty</strong> (similar to assuming the null true).</p>
<ul>
<li><strong>Type I Error</strong>: Convicting to defendant when they are innocent</li>
<li><strong>Type II Error</strong>: Failing to convict the defenant when they are guilty</li>
</ul>
</div>
<!-- Obtained from Scribbr -->
<p><img alt="ERROR_SOURCES" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/ERROR_SOURCES.png" /></p>
<p>The errors occur as a result of the <strong>overlap</strong> between the sampling distributions under the Null and Alternative:</p>
<!-- Obtained from Scribbr -->
<p><img alt="ERROR_DISTRIBUTION" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/ERROR_DISTRIBUTION.png" /></p>
<p>Consider a rejection of the null under the two possible scenarios:</p>
<ul>
<li>Sample is due to <strong>Variance</strong>; results in <strong>Type I Error</strong></li>
<li>Sample is due to <strong>Misspecification</strong>; results in <strong>True Positive</strong></li>
</ul>
<p>The significance level sets the <strong>threshold for extremeness</strong> which rules out variance, thus the probability of type I errors occuring IS the significance level of the test. In essence, if the sample is <strong>more extreme than it is likely to make this error</strong>, then the test is willing to take the risk to conclude that the null can be rejected.</p>
<p>Type II errors are essentially the opposite scenario - the sample is extreme, but <strong>not considered extreme enough</strong> under our significance level, causing it to fail to reject the null. Since the threshold for extremeness is the type I error, <strong>both errors are at odds with each other</strong>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Unlike confidence levels, the probability of a type I or II error occuring is for that <em>particular</em> test.</p>
</div>
<h4 id="test-statistics"><strong>Test Statistics</strong><a class="headerlink" href="#test-statistics" title="Permanent link">&para;</a></h4>
<p>In order to determine the p-value, the value of the sample statistic on the sampling distribution (percentile) must be determined. This value is known as the <strong>Test Statistic</strong>.</p>
<div class="arithmatex">\[
    \text{Test Statistic} = \frac{\hat{\theta} - \theta_{H_{0}}}{\text{SE}(\hat{\theta})}
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For instance, if the sampling distribution is normally distributed, this requires normalizing or studentizing the sample statistic.</p>
</div>
<p>Rather than compare the probabilities (which requires an additional step to convert from test statisic to probability), the test statistic itself can be compared to the corresponding <strong>percentile of the significance level</strong>, known as the <strong>Critical Value</strong>. The two comparisons are identical:</p>
<p><center></p>
<table>
<thead>
<tr>
<th align="center">Reject Null</th>
<th align="center">Do not Reject Null</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">p-value smaller than <span class="arithmatex">\(\alpha\)</span></td>
<td align="center">p-value smaller than <span class="arithmatex">\(\alpha\)</span></td>
</tr>
<tr>
<td align="center">Test statistic <em>larger</em> than critical value</td>
<td align="center">Test-statistic <em>smaller</em> than critical value</td>
</tr>
</tbody>
</table>
<p></center></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The area bounded by the critical value (area of the significance level) is known as the <strong>Critical Region</strong>.</p>
</div>
<!-- Obtained from Analyst Prep -->
<p><img alt="HYPOTHESIS_TESTING" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/HYPOTHESIS_TESTING.png" /></p>
<h4 id="link-to-confidence-intervals"><strong>Link to Confidence Intervals</strong><a class="headerlink" href="#link-to-confidence-intervals" title="Permanent link">&para;</a></h4>
<p>Confidence Intervals measure the <strong>range of values</strong> that the true parameter could lie. Hypothesis tests determine the <strong>reasonability</strong> of a hypothesized value. If both are determined on the same basis and the hypothesized value lies <strong>WITHIN the confidence interval</strong>, then the <strong>null hypothesised CANNOT be rejected</strong>.</p>
<p>Intuitively, this is because being within the confidence interval itself indicates that the <strong>value is reasonable</strong>, thus automatically failing the test. Mathematically, this is because any value within the confidence interval will <strong>always have a p-value greater than the significance level</strong>.</p>
<!-- Obtained from cqeacademy -->
<p><img alt="CONFIDENCE_INTERVAL_HYPOTHESIS" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/CONFIDENCE_INTERVAL_HYPOTHESIS.png" /></p>
<h2 id="maximum-likelihood-estimation"><strong>Maximum Likelihood Estimation</strong><a class="headerlink" href="#maximum-likelihood-estimation" title="Permanent link">&para;</a></h2>
<p>If the <strong>population distribution is known</strong>, there is an <strong>alternative method of estimating</strong> the parameters apart from calculating the corresponding sample statistics, known as <strong>Maximum Likelihood Estimation</strong> (MLE).</p>
<p>There are an infinite number of <strong>variations of the distribution</strong> that could have resulted in the sample, each with <strong>different parameters</strong>.</p>
<p>Technically speaking, any set of parameters could have resulted in the sample. However, the goal of MLE is to find the set of <strong>parameters that are most likely to result in the sample</strong>; in other words, the <strong>probability of obtaining this sample is the highest</strong> with this set of paramters than any other set.</p>
<p>The probability of obtaining the sample is known as its <strong>Likelihood</strong>:</p>
<div class="arithmatex">\[
     L(\theta \mid x) = P_{\theta} (X = x)
\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Likelihood functions and PMF/PDFs are often confused with one another as they involve the same expression.</p>
<p>The key is <strong>understanding what is given and what is random</strong>, which results in the subtle but differing notation:</p>
<ul>
<li><strong>PMF/PDF</strong>: Given parameters, outcomes are random; <span class="arithmatex">\(P_{X}(x)\)</span></li>
<li><strong>Likelihood</strong>: Given outcomes, parameters are random; <span class="arithmatex">\(P_{\theta}(x)\)</span></li>
</ul>
</div>
<p>Assuming that the sample is iid, the likehood for the entire sample is the <strong>product of the likelihood for each observation</strong>, known as the <strong>Likelihood Function</strong>:</p>
<div class="arithmatex">\[
    L(\theta) = \prod P_{\theta}(X = x_i)
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For discrete distributions, <span class="arithmatex">\(X = 0\)</span> is a <strong>valid observation</strong> and thus should be considered as well.</p>
</div>
<p>The goal is to find the parameters that <strong>maximizes</strong> the likelihood function through calculus:</p>
<div class="arithmatex">\[
    \frac{d}{d\theta} L(\theta) = 0
\]</div>
<p>In practice, especially when dealing with multiple parameters, the likelihood function is complicated to work with. Thus, a <strong>log transformation</strong> is often applied to simplify it, turning the <strong>product into a summation</strong>.</p>
<p>This is known as the <strong>Log-Likelihood Function</strong>. Since the logarithm transform is monotonic, both the likelihood and log-likelihood functions share the <strong>same maximum</strong>.</p>
<div class="arithmatex">\[
\begin{aligned}
    \ell (\theta) &amp;= \ln L(\theta) \\
    \therefore \frac{d}{d\theta} \ell (\theta) &amp;= 0
\end{aligned}
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The derivative of the log-likelihood function is known as the <strong>Score</strong>. It is equivalent to the <strong>gradient</strong> of the likelihood function:</p>
<p><!-- Obtained from Gaussian Waves -->
<img alt="SCORE_GRADIENT" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/SCORE_GRADIENT.png" /></p>
</div>
<h3 id="asymptotic-normality"><strong>Asymptotic Normality</strong><a class="headerlink" href="#asymptotic-normality" title="Permanent link">&para;</a></h3>
<p>It can be shown that as <span class="arithmatex">\(n \to \infty\)</span>, maximum likelihood estimates follow a normal distribution. In other words, they are <strong>Asymptotically Normally Distributed</strong>:</p>
<div class="arithmatex">\[
    \hat{\theta} \sim N \left(\theta, \frac{1}{I(\theta)} \right)
\]</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>The exact proof of why it is asymptotically normal requires heavy mathematics and is beyond the scope of this exam. It is sufficient to know that the <strong>Central Limit Theorem</strong> is a key part of the proof.</p>
</div>
<p>The term in the variance is known as <strong>Fisher's Information</strong>. It is a measure of the amount of information that an <strong>observed data point has about an underlying parameter</strong> used in its data generation process:</p>
<div class="arithmatex">\[
    I(\theta) = -E \left[\frac{\partial^{2} \ell(\theta)}{\partial \theta} \right]
\]</div>
<!-- Obtained from Guassian Waves -->
<p><img alt="INFORMATION_VARIANCE" class="center" src="../Assets/0.%20Review%20of%20Statistical%20Theory.md/INFORMATION_VARIANCE.png" /></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If the likelihood does not vary significantly, it means that the parameter is <strong>not sensitive to the data</strong>; data does not provide much underlying information. Thus, a likelihood which varies greatly has a <strong>large information</strong>.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>The variance of the asymptotic normal distribution is known as the <strong>Cramer Rao Lower Bound</strong>. It is the <strong>lowest possible variance</strong> that can be achieved for any unbiased estimator.</p>
<p>Intuitively, this is because MLE is an information based approach. When <span class="arithmatex">\(n \to \infty\)</span>, it uses ALL possible information, which is the <strong>theoretical best</strong> possible variance.</p>
</div>
<h3 id="practical-tips"><strong>Practical Tips</strong><a class="headerlink" href="#practical-tips" title="Permanent link">&para;</a></h3>
<p>Some distributions have complicated PMF/PDFs that make working with them more complicated. Most questions will usually have <strong>some method to simplify the likelihood function</strong>.</p>
<p>The first tip is to understand that since the likelihood function will be logarithm transformed and then differentiated, <strong>factors that contains ONLY constants can be dropped</strong> since they will inevitably be removed later:</p>
<div class="arithmatex">\[
\begin{aligned}
    L(\theta) &amp;= a * x \\
    \ell (\theta) &amp;= \ln a + \ln x \\
    \ell' (\theta) &amp;= \frac{1}{x} \\
    \\
    \therefore L(\theta) \propto x
\end{aligned}
\]</div>
<p>The next tip is that if the parameters are <strong>embedded in the power</strong> of some constant, they should be combined together:</p>
<div class="arithmatex">\[
\begin{aligned}
    L(\theta)
    &amp;= a^{\theta} \cdot b^{\theta} \cdot c^{\theta} \\
    &amp;= (a \cdot b \cdot c)^{\theta}
\end{aligned}
\]</div>
<p>The reverse also applies...divide power, may not be in the same term, could come from another term</p>
<p>However, if the above terms for some reason are <strong>added instead of multiplied</strong>, then a <strong>substituition</strong> method would be better:</p>
<div class="arithmatex">\[
\begin{aligned}
    L(\theta) &amp;= e^{-\frac{k}{100}} - \left(e^{-\frac{k}{100}} \right)^2 \\
    L(\theta) &amp;= p - p^2
\end{aligned}
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If multiple parameters are being estimated, then the likelihood function is <strong>partially differentiated</strong> to each variable instead</p>
<p>The MLE parameters are then the <strong>combination of parameters</strong> that maximizes the function. </p>
</div>
<h3 id="method-of-moments"><strong>Method of Moments</strong><a class="headerlink" href="#method-of-moments" title="Permanent link">&para;</a></h3>
<p>An alternative method for estimating population parameters is the <strong>Method of Moments</strong> (MOM).</p>
<p>It is based on the <strong>Law of Large Numbers</strong>, which states that the sample mean converges to the population mean (first raw moment), given a <strong>sufficiently large sample size</strong>.</p>
<p>Thus, by <strong>equating the sample raw moments to the population raw moments</strong>, up to the number of parameters to estimate, we can solve for an estimate of the parameters.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This process can be repeated for as many parameters there are:</p>
<ul>
<li><strong>One Parameter</strong>: First moments equated</li>
<li><strong>Two Parameters</strong>: First &amp; Second moment equated</li>
</ul>
<p>Most MLE questions will only require single parameter estimation. If two parameters are given, then there is <strong>usually some way to simplify it</strong>.</p>
</div>
<div class="arithmatex">\[
\begin{aligned}
    E(X^k)
    &amp;= \bar{x} \\
    &amp;= \frac{\sum x^k_i}{n}
\end{aligned}
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Needless to say, <span class="arithmatex">\(\bar{x}\)</span> represents the <strong>average of the quantity being modelled</strong>, NOT the number of observations.</p>
<p>If there are 10 observations of 2 claims, then we must compute the number of claims as <span class="arithmatex">\(10 \cdot 2 = 20\)</span>.</p>
</div>
<p>The main advantage of this method is that it is <strong>computationally simpler</strong> than MLE. For certain known distributions, the MOM estimate and MLE estimate are the same, thus MOM can be used as a <strong>shortcut for MLE</strong>.</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/8.%20Pensions/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Pensions" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Pensions
            </div>
          </div>
        </a>
      
      
        
        <a href="../1.%20Statistical%20Learning/" class="md-footer__link md-footer__link--next" aria-label="Next: Statistical Learning" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Statistical Learning
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.16e2a7d4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.5a2dcb6a.min.js"></script>
      
        <script src="../../../config/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
    
  </body>
</html>