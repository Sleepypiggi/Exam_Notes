
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://example.com/3_PREDICTIVE_ANALYTICS/0_ASA_SRM/6.%20Generalized%20Linear%20Models/">
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-8.5.10">
    
    
      
        <title>Generalized Linear Models - Exam Notes</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.975780f9.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.2505c338.min.css">
        
          
          
          <meta name="theme-color" content="#000000">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../config/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#generalized-linear-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Exam Notes" class="md-header__button md-logo" aria-label="Exam Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Exam Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Generalized Linear Models
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Exam Notes" class="md-nav__button md-logo" aria-label="Exam Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Exam Notes
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1">
          Introductory
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Introductory" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          Introductory
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../1_INTRODUCTORY/0.%20Review%20of%20Mathematics/" class="md-nav__link">
        Review of Mathematics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Placeholder/" class="md-nav__link">
        ASA P
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Placeholder/" class="md-nav__link">
        ASA FM
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_4" type="checkbox" id="__nav_1_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1_4">
          ASA IFM
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA IFM" data-md-level="2">
        <label class="md-nav__title" for="__nav_1_4">
          <span class="md-nav__icon md-icon"></span>
          ASA IFM
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_4_1" type="checkbox" id="__nav_1_4_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1_4_1">
          Derivatives
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Derivatives" data-md-level="3">
        <label class="md-nav__title" for="__nav_1_4_1">
          <span class="md-nav__icon md-icon"></span>
          Derivatives
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../1_INTRODUCTORY/2_ASA_IFM/1.%20Derivatives/1.%20Introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../1_INTRODUCTORY/2_ASA_IFM/1.%20Derivatives/3.%20Options/" class="md-nav__link">
        Options
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../1_INTRODUCTORY/2_ASA_IFM/1.%20Derivatives/5.%20Binomial%20Model/" class="md-nav__link">
        Binomial Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../1_INTRODUCTORY/2_ASA_IFM/1.%20Derivatives/6.%20Black%20Scholes%20Model/" class="md-nav__link">
        Black Scholes Model
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_4_2" type="checkbox" id="__nav_1_4_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1_4_2">
          Corporate Finance
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Corporate Finance" data-md-level="3">
        <label class="md-nav__title" for="__nav_1_4_2">
          <span class="md-nav__icon md-icon"></span>
          Corporate Finance
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../1_INTRODUCTORY/2_ASA_IFM/3.%20Corporate%20Finance/3.%20Risk%20Measures/" class="md-nav__link">
        Risk Measures
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Actuarial Mathematics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Actuarial Mathematics" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Actuarial Mathematics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_1" type="checkbox" id="__nav_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_1">
          ASA FAMS
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA FAMS" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          ASA FAMS
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/0.%20Short%20Term%20Insurance/" class="md-nav__link">
        Short Term Insurance
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/1.%20Review%20of%20Probability%20Theory/" class="md-nav__link">
        Review of Probability Theory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/2.%20Frequency%20Models/" class="md-nav__link">
        Frequency Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/3.%20Severity%20Models/" class="md-nav__link">
        Severity Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/4.%20Policy%20Modifications/" class="md-nav__link">
        Policy Modifications
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/5.%20Aggregate%20Models/" class="md-nav__link">
        Aggregate Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/6.%20Loss%20Reserving/" class="md-nav__link">
        Loss Reserving
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/7.%20Ratemaking/" class="md-nav__link">
        Ratemaking
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/8.%20Model%20Estimation/" class="md-nav__link">
        Model Estimation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/0_ASA_FAMS/9.%20Credibility%20Theory/" class="md-nav__link">
        Credibility Theory
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_2" type="checkbox" id="__nav_2_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_2">
          ASA FAML
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA FAML" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          ASA FAML
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/0.%20Long%20Term%20Insurance/" class="md-nav__link">
        Long Term Insurance
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/1.%20Survival%20Models/" class="md-nav__link">
        Survival Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/2.%20Life%20Tables/" class="md-nav__link">
        Life Tables
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/3.%20Life%20Assurances/" class="md-nav__link">
        Life Assurances
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/4.%20Life%20Annuities/" class="md-nav__link">
        Life Annuities
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/5.%20Variable%20Benefits/" class="md-nav__link">
        Variable Benefits
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/6.%20Premiums/" class="md-nav__link">
        Premiums
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/7.%20Reserves/" class="md-nav__link">
        Reserves
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/1_ASA_FAML/8.%20Model%20Estimation/" class="md-nav__link">
        Model Estimation
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_3" type="checkbox" id="__nav_2_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_3">
          ASA ALTAM
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA ALTAM" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_3">
          <span class="md-nav__icon md-icon"></span>
          ASA ALTAM
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/1.%20Multi%20Life%20Models/" class="md-nav__link">
        Multi Life Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/2.%20Multi%20Decrement%20Models/" class="md-nav__link">
        Multi Decrement Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/3.%20Multi%20State%20Models/" class="md-nav__link">
        Multi State Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/4.%20Multi%20State%20Applications/" class="md-nav__link">
        Multi State Applications
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/5.%20Profit%20Testing/" class="md-nav__link">
        Profit Testing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/6.%20Universal%20Life/" class="md-nav__link">
        Universal Life
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/7.%20Embedded%20Options/" class="md-nav__link">
        Embedded Options
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../2_ACTUARIAL_MATHEMATICS/2_ASA_ALTAM/8.%20Pensions/" class="md-nav__link">
        Pensions
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Predictive Analytics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Predictive Analytics" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Predictive Analytics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1" type="checkbox" id="__nav_3_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1">
          ASA SRM
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA SRM" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          ASA SRM
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../0.%20Review%20of%20Statistical%20Theory/" class="md-nav__link">
        Review of Statistical Theory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../1.%20Statistical%20Learning/" class="md-nav__link">
        Statistical Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../2.%20Simple%20Linear%20Regression/" class="md-nav__link">
        Simple Linear Regression
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../3.%20Multiple%20Linear%20Regression/" class="md-nav__link">
        Multiple Linear Regression
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../4.%20Linear%20Regression%20Assumptions/" class="md-nav__link">
        Linear Regression Assumptions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../5.%20Model%20Selection/" class="md-nav__link">
        Model Selection
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Generalized Linear Models
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Generalized Linear Models
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    Overview
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-concepts" class="md-nav__link">
    Key Concepts
  </a>
  
    <nav class="md-nav" aria-label="Key Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear-exponential-family" class="md-nav__link">
    Linear Exponential Family
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#link-functions" class="md-nav__link">
    Link Functions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maximum-likelihood" class="md-nav__link">
    Maximum Likelihood
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deviance" class="md-nav__link">
    Deviance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deviance-residual" class="md-nav__link">
    Deviance Residual
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statistical-inference" class="md-nav__link">
    Statistical Inference
  </a>
  
    <nav class="md-nav" aria-label="Statistical Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#likelihood-ratio-test" class="md-nav__link">
    Likelihood Ratio Test
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pearson-residuals" class="md-nav__link">
    Pearson Residuals
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dispersion" class="md-nav__link">
    Dispersion
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#categorical-models" class="md-nav__link">
    Categorical Models
  </a>
  
    <nav class="md-nav" aria-label="Categorical Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#binary-response" class="md-nav__link">
    Binary Response
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nominal-response" class="md-nav__link">
    Nominal Response
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ordinal-response" class="md-nav__link">
    Ordinal Response
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#count-models" class="md-nav__link">
    Count Models
  </a>
  
    <nav class="md-nav" aria-label="Count Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#poisson-model" class="md-nav__link">
    Poisson Model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dispersion_1" class="md-nav__link">
    Dispersion
  </a>
  
    <nav class="md-nav" aria-label="Dispersion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#negative-binomial" class="md-nav__link">
    Negative Binomial
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-inflated" class="md-nav__link">
    Zero Inflated
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hurdle-model" class="md-nav__link">
    Hurdle Model
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#heterogeneity-model" class="md-nav__link">
    Heterogeneity Model
  </a>
  
    <nav class="md-nav" aria-label="Heterogeneity Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#latent-class-models" class="md-nav__link">
    Latent Class Models
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../7.%20Tree%20Models/" class="md-nav__link">
        Tree Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../8.%20Principal%20Components/" class="md-nav__link">
        Principal Components
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../9.%20Clustering/" class="md-nav__link">
        Clustering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../10.%20Time%20Series/" class="md-nav__link">
        Time Series
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_2" type="checkbox" id="__nav_3_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_2">
          ASA PA
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ASA PA" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_2">
          <span class="md-nav__icon md-icon"></span>
          ASA PA
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../1_ASA_PA/0_OVERVIEW/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    Overview
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-concepts" class="md-nav__link">
    Key Concepts
  </a>
  
    <nav class="md-nav" aria-label="Key Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear-exponential-family" class="md-nav__link">
    Linear Exponential Family
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#link-functions" class="md-nav__link">
    Link Functions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maximum-likelihood" class="md-nav__link">
    Maximum Likelihood
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deviance" class="md-nav__link">
    Deviance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deviance-residual" class="md-nav__link">
    Deviance Residual
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#statistical-inference" class="md-nav__link">
    Statistical Inference
  </a>
  
    <nav class="md-nav" aria-label="Statistical Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#likelihood-ratio-test" class="md-nav__link">
    Likelihood Ratio Test
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pearson-residuals" class="md-nav__link">
    Pearson Residuals
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dispersion" class="md-nav__link">
    Dispersion
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#categorical-models" class="md-nav__link">
    Categorical Models
  </a>
  
    <nav class="md-nav" aria-label="Categorical Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#binary-response" class="md-nav__link">
    Binary Response
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nominal-response" class="md-nav__link">
    Nominal Response
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ordinal-response" class="md-nav__link">
    Ordinal Response
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#count-models" class="md-nav__link">
    Count Models
  </a>
  
    <nav class="md-nav" aria-label="Count Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#poisson-model" class="md-nav__link">
    Poisson Model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dispersion_1" class="md-nav__link">
    Dispersion
  </a>
  
    <nav class="md-nav" aria-label="Dispersion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#negative-binomial" class="md-nav__link">
    Negative Binomial
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-inflated" class="md-nav__link">
    Zero Inflated
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hurdle-model" class="md-nav__link">
    Hurdle Model
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#heterogeneity-model" class="md-nav__link">
    Heterogeneity Model
  </a>
  
    <nav class="md-nav" aria-label="Heterogeneity Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#latent-class-models" class="md-nav__link">
    Latent Class Models
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="generalized-linear-models"><strong>Generalized Linear Models</strong><a class="headerlink" href="#generalized-linear-models" title="Permanent link">&para;</a></h1>
<h2 id="overview"><strong>Overview</strong><a class="headerlink" href="#overview" title="Permanent link">&para;</a></h2>
<p>Linear Regression assumes that the dependent variable <strong>can change constantly and indefinitely</strong> in either direction, which is not appropriate for certain quantities that <strong>changes non-linearly</strong> or for values that can <strong>only take values of a certain range</strong> (EG. Positive only or between 0 and 1).</p>
<p>Another assumption made is that the dependent variable is normally distributed. Despite it being one of the most common distributions in reality, not all quantities follow it.</p>
<p>Thus, a <strong>Generalized Linear Model</strong> (GLM) overcomes the above two constraints by:</p>
<ol>
<li>Allowing the dependent variable to have a distribution from the <strong>Linear Exponential Family</strong> (LEF)</li>
<li>Specifying a <strong>link function</strong> that relates the dependent to the linear equation, allowing it to change <strong>non-linearly</strong></li>
</ol>
<!-- Obtained from Daily Dose of Data Science -->
<p><img alt="SLR_VS_GLM" class="center" src="../Assets/6.%20Generalized%20Linear%20Models.md/SLR_VS_GLM.png" /></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>It may be useful to think of them this way:</p>
<ul>
<li><strong>Distribution</strong>: Random component (Affecting errors)</li>
<li><strong>Link</strong>: Systematic component (Affecting the prediction)</li>
</ul>
</div>
<h2 id="key-concepts"><strong>Key Concepts</strong><a class="headerlink" href="#key-concepts" title="Permanent link">&para;</a></h2>
<h3 id="linear-exponential-family"><strong>Linear Exponential Family</strong><a class="headerlink" href="#linear-exponential-family" title="Permanent link">&para;</a></h3>
<p>The LEF of distributions encompasses a wide range of distributions, each with their own <strong>unique parameterization</strong>. However, they have common characteristics that allow them them to be <strong>re-parameterized</strong> into a common format:</p>
<div class="arithmatex">\[
\begin{aligned}
    \text{Y} &amp;\sim \text{LEF}(\theta, \phi) \\
    \\
    f(Y \mid \theta, \phi) &amp;= \exp \left(\frac{y \theta - b(\theta)}{\phi} + a(y, \phi) \right) \\
    \\
    E(Y) &amp;= b'(\theta) \\
    \text{Var}(Y) &amp;= \phi \cdot b''(\theta)
\end{aligned}
\]</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Apart from providing a common framework, re-paramterizing this way has certain mathematical properties which makes the resulting calculations smoother. It is not necessary to understand the intricate mathematical details.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The two parameters are referred to as the <strong>Canonical (<span class="arithmatex">\(\theta\)</span>) and the Dispersion (<span class="arithmatex">\(\phi\)</span>) Parameters</strong> respectively. They have no clear interpretation, it is sufficient to know that they affect the <strong>mean and variance</strong> respectively.</p>
<p>Consequently, the first and second derivatives are known as the <strong>Mean and Variance Function</strong> respectively. The key is remembering that the Variance is <strong>not entirely determined by the variance function</strong>, unlike the mean.</p>
<p>It is typically assumed that <span class="arithmatex">\(\phi\)</span> is a <strong>known constant</strong>.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>There are multiple ways to re-parameterize a PMF. Thus, it is important to know how to convert a PMF into LEF format:</p>
<ol>
<li>Introduce an <strong>exponential base</strong> to the function; <span class="arithmatex">\(x = e^{\ln x}\)</span></li>
<li>Assume <span class="arithmatex">\(\phi=1\)</span> unless otherwise stated</li>
<li>If there is a <strong>complicated standalone component</strong> involving <span class="arithmatex">\(y\)</span>, that is likely <span class="arithmatex">\(a(y, \phi)\)</span></li>
<li><strong>Factorize remaining <span class="arithmatex">\(y\)</span> terms</strong> to form <span class="arithmatex">\(y\theta\)</span>, the remaining terms should be <span class="arithmatex">\(b(\theta)\)</span></li>
</ol>
<p>Given additional information, the individual components might be able to be broken down again.</p>
</div>
<!-- Obtained from Coaching Actuaries -->
<p><img alt="LEF" class="center" src="../Assets/6.%20Generalized%20Linear%20Models.md/LEF.png" /></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Recall from earlier exams that the <strong>Exponential Distribution</strong> is a special case of the Gamma distribution. Thus, it is also part of the LEF and hence their canonical link functions are the same.</p>
<p>There is also a special distribution known as the <strong>Tweedie Distribution</strong> which is also part of the LEF. It is a <strong>Poisson Sum of Gamma Variables</strong>, which has properties <strong>somewhere between the two</strong> underlying distributions. It is a <strong>Discrete Continuous Mixture</strong> which allows for a large mass exactly at 0, making it particularly useful for modelling claims (aggregate losses).</p>
</div>
<!-- Self Made -->
<p><img alt="COMMON_GLM" class="center" src="../Assets/6.%20Generalized%20Linear%20Models.md/COMMON_GLM.png" /></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>It is possible to transform the underlying data to fit the requirements - EG. Adding a small positive constant to ensure all values are positive or non-negative.</p>
</div>
<h3 id="link-functions"><strong>Link Functions</strong><a class="headerlink" href="#link-functions" title="Permanent link">&para;</a></h3>
<p>Under linear regression, the model <strong>directly affects</strong> the dependent variable. Since the model changes linearly, the dependent variable <strong>must change linearly</strong> as well:</p>
<div class="arithmatex">\[
    E(Y \mid X)
    = \beta_{0} + \beta_{1} \cdot x_{1} + \beta_{2} \cdot x_{2} + \dots
\]</div>
<p>Thus, this can be overcome by introducing an <em>intermediate</em> <strong>Link Function</strong> between the dependent variable and the model output. Thus, even if the <strong>model changes linearly</strong>, the link function can cause a <strong>non-linear impact on the dependent variable</strong>:</p>
<div class="arithmatex">\[
\begin{aligned}
    E(Y \mid X)
    &amp;= g^{-1}(\beta_{0} + \beta_{1} \cdot x_{1} + \beta_{2} \cdot x_{2} + \dots) \\
    &amp;= g^{-1}(\boldsymbol{X}^{T} \boldsymbol{\beta}) 
\end{aligned}
\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>By definition, the link functions maps the dependent variable to the linear predictors. Hence, going the other way round, it is known as the <strong>Inverse Link Function</strong>.</p>
</div>
<p>The key consideration when choosing a link function is the <strong>domain</strong>:</p>
<ul>
<li>Linear Predictor generally has an <strong>unrestricted domain</strong> <span class="arithmatex">\((-\infty, \infty)\)</span></li>
<li>Dependent Variable generally has a <strong>restricted domain</strong> <span class="arithmatex">\((a, b)\)</span></li>
<li>Link function must be able to <strong>map the two domains together</strong></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Another consideration is <strong>interpretability</strong>. Since link functions directly impact the dependent variable, it is desirable to use a <strong>simpler function</strong> (all else equal) to ease understanding.</p>
<p>Ultimately, the link function should describe the relationship between the mean of the target variable and the linear predictors. For instance, if the relationship is linear, then the identity link can be used; no further transformation needed. But if the relationship IS non-linear, then another link can be used.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The link function is applied on the <strong>MEAN of the target variable</strong>, not the target variable itself. Thus, as long as the mean itself satisfies the domain of the link function, it can be used.</p>
<p>This is why Log link can be used for the Poisson distribution, even though values of 0 are allowed - because the mean is unlikely to be 0.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Due to the need to match domains, the link function (relationship between target and numeric predictors) must be <strong>monotonic</strong> - strictly increasing or decreasing.</p>
<p>Thus, if the relationship is non-linear, it would be better to use factor variables instead as they do not have this monotonic constraint.</p>
</div>
<!-- Self Made -->
<p><img alt="LINK_FUNCTION" class="center" src="../Assets/6.%20Generalized%20Linear%20Models.md/LINK_FUNCTION.png" /></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The existence of link functions means that the intepretation of regression coefficients is not the same as OLS. The effect on the predictor <strong>must consider the link function</strong> as well.</p>
</div>
<p>Within the subset of possible link functions, there exists a <strong>Canonical Link Function</strong> which is the <strong>Inverse Mean Function</strong>. This means that the linear predictor will be equivalent to the <strong>canonical parameter</strong> for the distribution:</p>
<div class="arithmatex">\[
\begin{aligned}
    \boldsymbol{X}^{T} \boldsymbol{\beta}
    &amp;= g \left[E(Y \mid X) \right] \\
    &amp;= b'^{-1} \left[E(Y \mid X) \right] \\
    &amp;= b'^{-1} \left[b'(\theta) \right] \\
    &amp;= \theta
\end{aligned}
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Parameter estimation is typically done through an iterative process, which <strong>may ultimately fail to converge</strong> to a solution. The canonical link <strong>simplifies the expression</strong>, which makes it easier to fit parameters, especially when there would have been issues.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Thus, if given an unknown mean function, the link function can be solved by solving for <span class="arithmatex">\(\theta\)</span>.</p>
</div>
<!-- Self Made -->
<p><img alt="CANONICAL_LINK" class="center" src="../Assets/6.%20Generalized%20Linear%20Models.md/CANONICAL_LINK.png" /></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Any <strong>multiplicative constant</strong> within the canonical link function itself does not make a difference to the result. An expression <strong>with or without</strong> the constant can be deemed as the Canonical Link function.</p>
<p>This INCLUDES the negative operator, as it can be viewed as a constant of -1.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Although most GLMs will use their canonical link, it is NOT a requirement that they will. Always read the question to check which link is being used!</p>
</div>
<p>It is important to choose a <strong>combination</strong> of distribution AND link that will result in the modelled target variable having a <strong>suitable domain</strong> (EG. Positive continuous values):</p>
<ul>
<li><strong>Distribution</strong>: Directly consider characteristics of the target variable (Domain, Spread etc)</li>
<li><strong>Link Function</strong>: Consider whether resulting predictions are valid realizations of the distribution</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>It is important to know the difference between the following:</p>
<table>
<thead>
<tr>
<th align="center"><strong>GLM Log Link</strong></th>
<th align="center"><strong>MLR Log Transform</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><span class="arithmatex">\(\ln[E(Y \mid X)]\)</span></td>
<td align="center"><span class="arithmatex">\(E[\ln (Y \mid X)]\)</span></td>
</tr>
<tr>
<td align="center">Directly models relationship</td>
<td align="center">Indirectly models the relationship</td>
</tr>
<tr>
<td align="center">Indirectly controls variance (via Mean)</td>
<td align="center">Directly stabilizes the mean</td>
</tr>
<tr>
<td align="center">Easier to interpret (Original target)</td>
<td align="center">Harder to intepret (Transformed target)</td>
</tr>
<tr>
<td align="center">Any LEF distribution</td>
<td align="center">Normal distribution</td>
</tr>
</tbody>
</table>
</div>
<h3 id="maximum-likelihood"><strong>Maximum Likelihood</strong><a class="headerlink" href="#maximum-likelihood" title="Permanent link">&para;</a></h3>
<p>The parameters are estimated using <strong>Maximum Likelihood Estimation</strong> (MLE), where the likelihood function can be expressed as the following:</p>
<div class="arithmatex">\[
\begin{aligned}
    \ell(\beta)
    &amp;= \ln \prod \exp \left(\frac{y \theta - b(\theta)}{\phi} + a(y, \phi) \right) \\
    &amp;= \sum \ln \exp \left(\frac{y \theta - b(\theta)}{\phi} + a(y, \phi) \right) \\
    &amp;= \sum \left(\frac{y \theta - b(\theta)}{\phi} + a(y, \phi) \right) \\
    \\
    \frac{\partial^{2} \beta}{\partial \beta^{2}} &amp;= 0
\end{aligned}
\]</div>
<p>Since <span class="arithmatex">\(\beta\)</span> and <span class="arithmatex">\(\theta\)</span> are linked, solving for <span class="arithmatex">\(\beta\)</span> provides <span class="arithmatex">\(\theta\)</span> as well. It is typically asummed that <span class="arithmatex">\(\phi\)</span> is 1 for most key distributions.</p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>There are <strong>no closed form solutions</strong> to the above system of equations, they are typically solved through numerical methods. It is not necessary to know the details for this exam.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Recall that MLE achieves <strong>Asymptotic Normality</strong>. This will be the basis used for GLM-related statistical inference. The actual normal distribution will be used (rather than t-distribution) because in the limit, the variance of the normal distribution is <strong>known</strong>.</p>
<p>However, the "adequateness" of the asymptotic results are dependent on the <strong>choice of distribution</strong>, but not the distribution of the underlying data:</p>
<ul>
<li>Consider a <strong>continuous</strong> dataset with <strong>equal mean and variance</strong></li>
<li>The key is to choose a distribution with <strong>equal mean and variance as well</strong>, regardless of what the underlying distribution is</li>
<li>For instance, if a poisson distribution was used, it is technically "wrong" because it assumes discrete data while the underlying data is continuous, but since it models the mean and variance correctly, it can be used</li>
</ul>
</div>
<h3 id="deviance"><strong>Deviance</strong><a class="headerlink" href="#deviance" title="Permanent link">&para;</a></h3>
<p>For linear rgeression, the parameters were estimated based on the residuals; thus, the goodness of fit was measured using the residuals via ANOVA. Similarly, since GLMs use MLE, their fit should be <strong>measuring using likelihood</strong>.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Naturally, this means that traditional ANOVA measures are NOT applicable in a GLM context.</p>
</div>
<p>Consider an extreme case of GLM where the <strong>number of parameters in the model is exactly equal to the number observations</strong>, causing it to <strong>fit the data perfectly</strong>. This is known as a <strong>Saturated Model</strong>. This saturated model obviously suffers from overfitting (as it perfectly captures the noise in each sample), thus should not be used for prediction.</p>
<p>However, it can be used as a <strong>benchmark</strong> for the total information available in the sample and consequently <strong>how much is lost</strong> through the fitting process. This is measured via the <strong>Deviance</strong> of the model, which is the <strong>difference in the likelihood</strong> of the two models:</p>
<div class="arithmatex">\[
    D^{*} = 2 \cdot (\ell_{\text{Saturated}} - \ell_{\text{Fitted}})
\]</div>
<p>The above are the <strong>MAXIMIZED log-likelihoods</strong>, which uses the likelihoods with the <strong>MLE estimate</strong>:</p>
<ul>
<li><strong>Saturated</strong>: Uses actual observations (Since a saturated model fits the data perfectly)</li>
<li><strong>Fitted</strong>: Uses fitted observations</li>
</ul>
<p>The fitted model should have <strong>sufficiently high likelihood</strong> to ensure that it captures the signals, but be reasonably smaller than the saturated model to prevent overfitting. Thus, models with <strong>smaller (but NOT too small) deviance</strong> are preferred.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The subtraction of the two likelihoods would cause the second term in the probability function to cancel, leaving only the difference in the numerators:</p>
<div class="arithmatex">\[
    D^{*} = \frac{D}{\varphi}
\]</div>
<p>Thus, the most accurate terminology would be that the difference in the two likelihoods is known as the <strong>Scaled Deviance</strong>, while the differences in the numerator only is the <strong>Deviance</strong>. However, since <span class="arithmatex">\(\varphi\)</span> is <strong>typically assumed to be 1</strong> for most distributions used in SRM, the two are <strong>identical</strong>.</p>
<p>Another reason is that under GLM, the total variance <strong>CANNOT be decomposed</strong> into Explained and Unexplained components; there is an addittional component:</p>
<div class="arithmatex">\[
\begin{aligned}
    \text{TSS}
    &amp;= \sum(y_{i} - \hat{y})^{2} + \sum(\hat{y} - \bar{y})^{2}
        + 2 \sum \left([y_{i} - \hat{y}][\hat{y}-\bar{y}] \right) \\
    &amp;= \text{RSS} + \text{RegSS} + 2 \sum \left([y_{i} - \hat{y}][\hat{y}-\bar{y}] \right)
\end{aligned}
\]</div>
<p>The above additional component would cancel out under OLS, thus was not issue. However, this <strong>does NOT apply to GLMs</strong>. Thus, the usual <strong>ANOVA inferences do NOT apply in a GLM context</strong>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Consider the Likelihood for the following two distributions - Binomial and Poisson. The key is understanding that whenever the predicted quantity (<span class="arithmatex">\(\pi\)</span> or <span class="arithmatex">\(\lambda\)</span>) comes up in the equation:</p>
<ul>
<li><strong>Saturated Likelihood</strong>: Fill in the actual observation (since perfectly predict)</li>
<li><strong>Fitted Likelihood</strong>: Fill in the predicted value</li>
<li>Terms with JUST the observed value will naturally cancel out during the deviance process</li>
</ul>
<div class="arithmatex">\[
\begin{aligned}
    L_{\text{Binomial}} &amp;= \sum {n \choose y} \pi^{y} (1 - \pi)^{n-y} \\
    \ell_{\text{Binomial}} &amp;= \sum y \ln \pi + (n-y) \ln (1 - \pi) \\
    \ell_{\text{Poisson, Saturated}} &amp;= \sum y_{i} \ln y_{i} + (n - y_{i}) \ln (1 - y_{i}) \\
    \ell_{\text{Poisson, Fitted}} &amp;= \sum y_{i} \ln \hat{y}_{i} + (n - \hat{y}_{i}) \ln (1 - \hat{y}_{i}) \\
    \\
    \therefore D^{*}_{\text{Binomial}}
    &amp;= 2 \cdot (\ell_{\text{Binomial, Saturated}} - \ell_{\text{Binomial, Fitted}}) \\
    &amp;= 2 \cdot \sum \left[ (y_{i} \ln y_{i} - y_{i} \ln \hat{y}_{i}) + ((n - y_{i}) \ln (1 - y_{i}) - (n - \hat{y}_{i}) \ln (1 - \hat{y}_{i})) \right] \\
    &amp;= 2 \cdot \sum \left[ y_{i} \ln \frac{y_{i}}{\hat{y}_{i}} + (n - y_{i}) \ln \frac{1 - y_{i}}{1 - \hat{y}_{i}} \right] \\
    \\
    L_{\text{Poisson}} &amp;= \sum \frac{\lambda^{y} e^{-\lambda}}{y!} \\
    \ell_{\text{Poisson}} &amp;= \sum y \ln \lambda - \lambda - \ln y! \\
    \ell_{\text{Poisson, Saturated}} &amp;= \sum y_{i} \ln y_{i} - y_{i} - \ln y_{i}! \\
    \ell_{\text{Poisson, Fitted}} &amp;= \sum y_{i} \ln \hat{y}_{i} - \hat{y}_{i} - \ln y_{i}! \\
    \\
    \therefore D^{*}_{\text{Poisson}}
    &amp;= 2 \cdot (\ell_{\text{Poisson, Saturated}} - \ell_{\text{Poisson, Fitted}}) \\
    &amp;= 2 \cdot \sum \left[ (y_{i} \ln y_{i} - y_{i} \ln \hat{y}_{i}) - (y_{i} - \hat{y}_{i}) - (\ln y_{i}! - \ln y_{i}!) \right] \\
    &amp;= 2 \cdot \sum \left[ y_{i} \ln \left(\frac{y_{i}}{\hat{y}_{i}} \right) - (y_{i} - \hat{y}_{i}) \right] \\
\end{aligned}
\]</div>
<p>For a <strong>normal distribution</strong>, in other words regular linear regression, the Deviance is equivalent to the <strong>RSS</strong>.</p>
</div>
<p>The concept of deviance is similar to goodness of fit, thus can be used similarly to R-squared, known as <strong>Pseduo R-squared</strong>:</p>
<div class="arithmatex">\[
    R^{2}_{\text{Pse}}
    = \frac{\ell_{\text{fitted}} - \ell_{\text{Null}}}{\ell_{\text{Sat}} - \ell_{\text{Null}}}
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The key idea remains the same. It is the proportion of Deviance explained by the model over the total possible deviance that could be explained. The key difference is that the values are <strong>relative to the likelihoods of the null model</strong> - representing the change in likelihood from the model parameters.</p>
</div>
<h3 id="deviance-residual"><strong>Deviance Residual</strong><a class="headerlink" href="#deviance-residual" title="Permanent link">&para;</a></h3>
<p>Recall that since the likelihood is already a sum of each observation, there exists a deviance for each observation as well. The squareroot of that amount is known as the <strong>Deviance Residual</strong>:</p>
<div class="arithmatex">\[
\begin{aligned}
    D^{*}
    &amp;= \sum D^{*}_{i} \\
    \\
    \text{Deviance Residual}
    &amp;= \text{sign}(y_{i} - \hat{y}_{i}) \sqrt{D^{*}_{i}} \end{aligned}
\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Only the SIGN of the deviance residuals follow the raw residual. Thus, a positive residual represents under-prediction and vice-versa.</p>
<p>Otherwise, the two are completely <strong>different concepts</strong> - do NOT confuse them!</p>
</div>
<h2 id="statistical-inference"><strong>Statistical Inference</strong><a class="headerlink" href="#statistical-inference" title="Permanent link">&para;</a></h2>
<h3 id="likelihood-ratio-test"><strong>Likelihood Ratio Test</strong><a class="headerlink" href="#likelihood-ratio-test" title="Permanent link">&para;</a></h3>
<p>Similar to how F-tests made use of the ANOVA results to perform statistical inference, GLMs can make use of the Deviance results in a similar fashion, via a <strong>Likelihood Ratio Test (LRT)</strong>, which compares a pair of <strong>NESTED GLMs</strong>:</p>
<ul>
<li><span class="arithmatex">\(H_{0}\)</span>: <span class="arithmatex">\(\beta_{q} = 0\)</span></li>
<li><span class="arithmatex">\(H_{1}\)</span>: <span class="arithmatex">\(\beta_{q} \ne 0\)</span></li>
</ul>
<div class="arithmatex">\[
\begin{aligned}
    \chi_{\text{Statistic}}
    &amp;= 2 \cdot (\ell_{\text{Full}} - \ell_{\text{Restricted}}) \\
    &amp;= 2 \cdot (\ell_{\text{Full}} - \ell_{\text{Saturated}} + \ell_{\text{Saturated}} - \ell_{\text{Restricted}}) \\
    &amp;= 2 \cdot (\ell_{\text{Full}} - \ell_{\text{Saturated}}) + 2 \cdot (\ell_{\text{Saturated}} - \ell_{\text{Restricted}}) \\
    &amp;= - 2 \cdot (\ell_{\text{Saturated}} - \ell_{\text{Full}}) + 2 \cdot (\ell_{\text{Saturated}} - \ell_{\text{Restricted}}) \\
    &amp;= 2 \cdot (\ell_{\text{Saturated}} - \ell_{\text{Restricted}}) - 2 \cdot (\ell_{\text{Saturated}} - \ell_{\text{Full}}) \\
    &amp;= D_{\text{Restricted}} - D_{\text{Full}} \\
    \\
    \chi_{\text{Statistic}} &amp;\sim \chi^{2}_{p_{\text{Full}} - p_{\text{Restricted}}}
\end{aligned}
\]</div>
<p>If there is a <strong>significant drop in likelihood</strong> between the two models, then the reduced predictors are significant and thus should not be dropped from the model.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Even though Ratio is in the name, the test-statistic is NOT ratio of likelihoods.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>For the purposes of this exam, it is typically assumed that the restricted model is the null model; similar overall set-up to an F-test.</p>
</div>
<h3 id="pearson-residuals"><strong>Pearson Residuals</strong><a class="headerlink" href="#pearson-residuals" title="Permanent link">&para;</a></h3>
<p>Pearson Residuals are the raw residuals <strong>scaled by the standard deviation</strong>:</p>
<div class="arithmatex">\[
    e_{\text{Pearson}} = \frac{y - \hat{y}}{\sqrt{\hat{\text{Var}}(y)}}
\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The standard deviation is from the variance of the underlying distribution, NOT of the coefficients or the sort:</p>
<ul>
<li>Binomial: <span class="arithmatex">\(\text{Var(Y)} = np(1-p)\)</span></li>
<li>Poisson: <span class="arithmatex">\(\text{Var(Y)} = \mu\)</span></li>
</ul>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>For the poisson distribution specifically, the reason why Pearson residuals are used is because the raw residuals are expected to be <strong>Heteroscedastic</strong>.</p>
<p>Another interesting effect is that the <strong>SUM OF SQUARED pearson residuals</strong> is equivalent to the Chi-Square goodness of fit:</p>
<div class="arithmatex">\[
\begin{aligned}
     \text{Pearson Goodness of Fit}
     &amp;= \sum e^{2}_{\text{Pearson}} \\
     &amp;= \sum \left(\frac{y - \hat{y}}{\sqrt{\hat{\text{Var}}(y)}} \right)^{2} \\
     &amp;= \sum \left(\frac{(y - \hat{y})^{2}}{\hat{\text{Var}}(y)} \right) \\
     &amp;= \sum \left(\frac{(y - \mu)^{2}}{\mu} \right) \\
     &amp;\approx \sum \frac{(O - E)^{2}}{E} \\
     &amp;\approx \text{Chi Square Goodness of fit} \\
     \\
     \text{Pearson Goodness of Fit} &amp;\sim n - p -1
\end{aligned}
\]</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Generally, why "normal" residuals are not useful in GLMs is because each model follows a <strong>different distribution</strong>, thus there are is <strong>no uniform behaviour for raw residuals</strong>.</p>
<p>However, as they are stills residuals, they can be used in a <strong>similar way</strong> - to find outliers or identify misspecification.</p>
</div>
<h3 id="dispersion"><strong>Dispersion</strong><a class="headerlink" href="#dispersion" title="Permanent link">&para;</a></h3>
<p>Recall that for MLR, Homoscedasticity (constant variance) was an assumption made about the data. More generally for GLMs, there is also an <strong>assumption made about the variance</strong> of the target, which is based on the <strong>choice of distribution</strong>. If the actual distribution has a variance different from what was assumed:</p>
<ul>
<li><strong>Overdispersion</strong>: Actual variability is larger than expected; <strong>standard errors understated</strong>; false positives</li>
<li><strong>Underdispersion</strong>: Actual variability is smaller than expected; <strong>standard errors overstated</strong>; false negative</li>
</ul>
<p>Apart from changing the distribution of choice to better match the data (EG. Negative Binomial rather than Poisson due to flexibility), another is to use the <strong>Quasi Likelihood Method</strong>. This works by estimating a <strong>new dispersion parameter</strong> (<span class="arithmatex">\(\delta\)</span>) such that it is a <strong>Pearson Goodness of Fit Statistic scaled by its degrees of freedom</strong>: </p>
<div class="arithmatex">\[
    \delta = \frac{1}{n-p-1} \cdot \text{Pearson Goodness of Fit} \\
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>This also means that the pearson chi-squared statistic can also be used to <strong>indicate when large over-dispersion is present</strong>, since the adjustment required is <strong>proportional to the amount needed to re-scale</strong> the variance. Thus, another definition for dispersion is the <strong>relative size of the Deviance compared to its degrees of freedom</strong>.</p>
</div>
<p>The above method only works for distributions which have a <strong>restrictive variance</strong>; the existing dispersion parameter is fixed (<span class="arithmatex">\(\phi = 1\)</span>). However, applying this method fixes the dispersion but also fundamentally "changes" the distribution to become fake ("Quasi"):</p>
<ul>
<li>Coefficients remain unchanged</li>
<li>Standard errors should increase</li>
<li>Aymptotic normality no longer holds; t-distribution should be used instead</li>
<li>Interpretation should change</li>
<li>Log-likelihood doesnt make sense</li>
</ul>
<h2 id="categorical-models"><strong>Categorical Models</strong><a class="headerlink" href="#categorical-models" title="Permanent link">&para;</a></h2>
<h3 id="binary-response"><strong>Binary Response</strong><a class="headerlink" href="#binary-response" title="Permanent link">&para;</a></h3>
<p>A Binary response variable has only two outcomes (0,1), thus a <strong>Bernoulli Distribution</strong> is used to model it. There are <strong>three main link functions</strong> that can map the the range into (0,1):</p>
<ul>
<li><strong>Logit Link</strong>: <span class="arithmatex">\(\ln \frac{\mu}{1-\mu}\)</span></li>
<li><strong>Probit Link</strong>: <span class="arithmatex">\(\Phi^{-1}(\mu)\)</span></li>
<li><strong>Complementary Log-Log Link</strong>: <span class="arithmatex">\(\ln[- \ln(1-\mu)]\)</span></li>
</ul>
<!-- Obtained from Coaching Actuaries -->
<p><img alt="BINARY_LINK" class="center" src="../Assets/6.%20Generalized%20Linear%20Models.md/BINARY_LINK.png" /></p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Recall the difference the function and the link function:</p>
<div class="arithmatex">\[
\begin{aligned}
    Z &amp;= \ln \left( \frac{P}{1-P} \right) \\
    e^{Z} &amp;= \frac{P}{1-P} \\
    e^{Z} - P \cdot e^{Z} &amp;= P \\
    P + P \cdot e^{Z} &amp;= e^{Z} \\
    P (1 + e^{Z}) &amp;= e^{Z} \\
    P &amp;= \frac{e^{Z}}{1 + e^{Z}} \\
    \therefore \text{Logit} &amp;= \frac{e^{Z}}{1 + e^{Z}} \\ 
    \\
    Z &amp;= \Phi^{-1}(P) \\
    P &amp;= \phi(Z) \\
    \therefore \text{Probit} &amp;= \phi(Z) \\
    \\
    Z &amp;= \ln (- \ln(1-p)) \\
    e^{Z} &amp;= - \ln (1-p) \\
    -e^{Z} &amp;= \ln (1-p) \\
    e^{-e^{z}} &amp;= 1 - p \\
    P &amp;= 1 - e^{-e^{z}}
\end{aligned}
\]</div>
<p><!-- Self Made -->
<img alt="LOGIT_VS_LOGIT_LINK" class="center" src="../Assets/6.%20Generalized%20Linear%20Models.md/LOGIT_VS_LOGIT_LINK.png" /></p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Notice the similarities between the three:</p>
<ul>
<li><strong>Negative IV</strong>: Complementary Log-Log &amp; Logit are similar</li>
<li><strong>Positive IV</strong>: Complementary Log-Log &amp; Probit are similar</li>
</ul>
<p>Generally speaking, it is <strong>NOT EASY</strong> to distinguish between the three methods graphically.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Logit and Probit are the most popular methods. However, logit is preferred as it is;</p>
<ol>
<li>The canonical link for the Binomial distribution</li>
<li>Can be expressed in a closed form</li>
<li>Easier to intepret</li>
</ol>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Logistic Regression exists in a grey area:</p>
<ul>
<li>It is technically a <strong>regression method</strong> as it estimates a <strong>continuous value of probabilities</strong></li>
<li>However, it is also regarded as a <strong>classification method</strong> as it ultimately predicts one of two <strong>categories</strong> </li>
</ul>
</div>
<p>Logit is the canonical link function; the resulting GLM is known as a <strong>Logistic Regression</strong>. It models the <strong>Log-Odds</strong> of an event occuring:</p>
<div class="arithmatex">\[
\begin{aligned}
    \ln \frac{1-\mu}{\mu} &amp;= \beta_{0} + \beta_{1} \cdot X_{1} + \dots \\
    \frac{1-\mu}{\mu} &amp;= \exp (\beta_{0} + \beta_{1} \cdot X_{1} + \dots) \\
    \text{Odds} &amp;= \exp (\beta_{0} + \beta_{1} \cdot X_{1} + \dots) \\
    \\
    \therefore \ln \text{Odds} &amp;= Y \\
    \frac{1-\mu}{\mu} &amp;= e^{Y} \\
    \mu &amp;= e^{Y} - \mu \cdot e^{Y} \\
    \mu &amp;= \frac{e^{Y}}{1 + e^{Y}} \\
    \text{P(A)} &amp;= \frac{e^{Y}}{1 + e^{Y}}
\end{aligned}
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Odds is the <strong>ratio of the probability</strong> of an event occuring to it not occuring:</p>
<div class="arithmatex">\[
    \text{Odds} = \frac{\text{P(A)}}{1 - \text{P(A)}}
\]</div>
<p>It is an alternative way of representing probabilities, typically used in a gambling context.</p>
</div>
<p>It can be shown that the exponent of the regression coefficient is the <strong>multiplicate increase in the odds</strong> given a one unit increae in that variable (continuous) or presence of that variable (categorical):</p>
<div class="arithmatex">\[
\begin{aligned}
    \frac{\text{Odds}_{1}}{\text{Odds}_{0}}
    &amp;= \frac{\exp (\beta_{0} + \beta_{1} \cdot (X_{1}+1))}{\exp (\beta_{0} + \beta_{1} \cdot X_{1})} \\
    &amp;= \exp (\beta_{1}) \\
    \\
    \text{Percentage Change} &amp;= \exp (\beta_{1}) - 1
\end{aligned}
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The primary motivation for the Logistic Regression is because a <strong>regular linear model</strong> is unable to effectively model dummy variables due to the following limitations:</p>
<ul>
<li><strong>Domain Mismatch</strong>: Linear models range from negative to positive infinity; Probabilities can only range from 0 to 1</li>
<li><strong>Heteroscedasticity</strong>: Linear models require homoscedasticity; Bernouilli exhibits heteroscedasticity (variance function linked to mean)</li>
<li><strong>Invalid Residuals</strong>: Linear models require continuous residuals; Residuals for probabilities dont make sense</li>
</ul>
</div>
<p>The output of the logistic regression is the Odds of the event, which can be converted into probability. At this point, a <strong>cutoff</strong> must be chosen such that all probabilities <strong>above the cutoff</strong> will be classified as the event of interest occuring.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>0.5 is often chosen as the cutoff value - but it can also be algorithmically determined via AUC.</p>
</div>
<h3 id="nominal-response"><strong>Nominal Response</strong><a class="headerlink" href="#nominal-response" title="Permanent link">&para;</a></h3>
<p>For a variable with more than two levels, a <strong>Generalized Logit Model</strong> is used. Rather than odds, it models the log of the <strong>relative probability</strong> of the target category and reference category.</p>
<p>For a variable with <span class="arithmatex">\(k\)</span> categories, <span class="arithmatex">\(k-1\)</span> models will be fitted, for each of the <strong>non-reference</strong> categories:</p>
<div class="arithmatex">\[
\begin{aligned}
    \ln \left(\frac{P(1)}{P(k)} \right) &amp;= \beta_{1} + \beta_{1, 1} \cdot X \\
    \ln \left(\frac{P(2)}{P(k)} \right) &amp;= \beta_{2} + \beta_{1, 2} \cdot X \\
    \ln \left(\frac{P(3)}{P(k)} \right) &amp;= \beta_{3} + \beta_{1, 3} \cdot X
\end{aligned}
\]</div>
<p>The system of equations above will result in <span class="arithmatex">\(k-1\)</span> equations (since the last category does not have its own equation) for <span class="arithmatex">\(k\)</span> unknowns. The final equation is the fact that the unknowns are probabilities, thus all have to <strong>sum to 1</strong>:</p>
<div class="arithmatex">\[
    P(1) + P(2) + P(3) + \dots = 1
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the model has <span class="arithmatex">\(p\)</span> predictors and <span class="arithmatex">\(k\)</span> categories, then a total of <span class="arithmatex">\(p \cdot (k-1)\)</span> coefficients are needed, reflecting the above fact.</p>
</div>
<h3 id="ordinal-response"><strong>Ordinal Response</strong><a class="headerlink" href="#ordinal-response" title="Permanent link">&para;</a></h3>
<p>When there is an Order to the nominal variables, they are distinguished based on their <strong>cumulative probabilities</strong>. In essence, the prediction space is split into <strong>distinct regions</strong> representing each of the categories:</p>
<!-- Obtained from Medium -->
<p><img alt="ORDINAL_TAU_CUTS" class="center" src="../Assets/6.%20Generalized%20Linear%20Models.md/ORDINAL_TAU_CUTS.png" /></p>
<p>There are will always be <strong><span class="arithmatex">\(k-1\)</span> cut points</strong> which are always <strong>non-decreasing</strong>. Thus, a larger prediction which will lead to a <strong>"higher" category</strong>, hence preserving the order of the prediction.</p>
<p>In terms of modelling, a <strong>Cumulative Logit Model</strong> is used, which models the <strong>cumulative odds</strong> of each of the categories except the last. Given the system of equations, the <strong>probabilities for each category</strong> can be determined. The prediction of the model is the category with the <strong>highest probability</strong>:</p>
<ul>
<li><span class="arithmatex">\(\alpha\)</span>: Cut Points</li>
<li><span class="arithmatex">\(\beta_{j}\)</span>: Regression coefficient</li>
</ul>
<div class="arithmatex">\[
\begin{aligned}
    \ln \left(\frac{P(1)}{1 - P(1)} \right) &amp;= \alpha_{1} + \beta_{1, 1} \cdot X \\
    \ln \left(\frac{P(1) + P(2)}{1 - (P(1) + P(2))} \right) &amp;= \alpha_{2} + \beta_{1, 2} \cdot X \\
    \ln \left(\frac{P(1) + P(2) + P(3)}{1 - (P(1) + P(2) + P(3))} \right) &amp;= \alpha_{3} + \beta_{1, 3} \cdot X
\end{aligned}
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Similar to before, the model only provides <span class="arithmatex">\(k-1\)</span> equations for <span class="arithmatex">\(k\)</span> probabilities to be solved for. Thus, the same approach can be taken to solve for the final probability:</p>
<div class="arithmatex">\[
    P(1) + P(2) + P(3) + \dots = 1
\]</div>
<p>Similarly, the model requires a large number of coefficients to be estimated, one set for each of the modelled <span class="arithmatex">\(k-1\)</span> categories.</p>
</div>
<p>A common variation of is to use the <strong>Proportional Odds</strong> Cumulative Model. It assumes that the <strong>odds ratios are the same across thresholds</strong>, thus allowing each equation to use the <strong>SAME <span class="arithmatex">\(\beta\)</span></strong>, with only the <span class="arithmatex">\(\alpha\)</span> changing for each, reducing the number of cofficients needed:</p>
<div class="arithmatex">\[
\begin{aligned}
    \ln \left(\frac{P(1)}{1 - P(1)} \right) &amp;= \alpha_{1} + \beta_{1} \cdot X \\
    \ln \left(\frac{P(1) + P(2)}{1 - (P(1) + P(2))} \right) &amp;= \alpha_{2} + \beta_{1} \cdot X \\
    \ln \left(\frac{P(1) + P(2) + P(3)}{1 - (P(1) + P(2) + P(3))} \right) &amp;= \alpha_{3} + \beta_{1} \cdot X
\end{aligned}
\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>It is simply that the <span class="arithmatex">\(\beta\)</span>'s are constant across predictions, not that they are not needed.</p>
<p>In the event that the base model already does not include any predictors (simplest null model) then the proportional odds model does not provide any advantage.</p>
</div>
<p>Thus, it can be easily seen that the <strong>ratio of two cumulative odds</strong> is simply the difference in cut points:</p>
<div class="arithmatex">\[
\begin{aligned}
    \frac{\frac{P(1)}{1 - P(1)}}{\frac{P(1) + P(2)}{1 - (P(1) + P(2))}}
    &amp;= \frac{\exp (\alpha_{1} + \beta_{1} \cdot X)}{\exp (\alpha_{2} + \beta_{1} \cdot X)} \\
    &amp;= \exp (\alpha_{1} - \alpha_{2})
\end{aligned}
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>This is useful for situations where the same model is used to make predictions for different observations. If the outcome for one observation is known, then the other can be easily solved.</p>
</div>
<h2 id="count-models"><strong>Count Models</strong><a class="headerlink" href="#count-models" title="Permanent link">&para;</a></h2>
<h3 id="poisson-model"><strong>Poisson Model</strong><a class="headerlink" href="#poisson-model" title="Permanent link">&para;</a></h3>
<p>Since counts are non-negative integers, the <strong>Poisson Distribution</strong> can be used. The canonical link is the <strong>natural log</strong>, where the resulting model is known as a <strong>Poisson Count Model</strong>. It models the <strong>log of the mean</strong>, where the exponent of the regression coefficients represent a <strong>multiplicative increase</strong> in the mean:</p>
<div class="arithmatex">\[
    \ln \mu = \beta_{0} + \beta_{1} \cdot X_{1} + \dots
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Count models are sometimes also known as <strong>Frequency</strong> Models.</p>
</div>
<p>Recall that the poisson distribution can be interpreted as the <strong>average number of occurences for a given exposure</strong> (w). The average thus be re-expressed as a combination of exposure and occurrence per exposure (rate, <span class="arithmatex">\(\lambda\)</span>):</p>
<div class="arithmatex">\[
    \mu = w \cdot \lambda
\]</div>
<p>If the underlying data has <strong>different subgroups with different exposures</strong>, it will be more appropriate to model the <strong>rate per exposure</strong> rather than the actual count:</p>
<div class="arithmatex">\[
\begin{aligned}
    \ln \lambda &amp;= \beta_{0} + \beta_{1} \cdot X_{1} + \dots \\
    \ln \frac{\mu}{w} &amp;= \beta_{0} + \beta_{1} \cdot X_{1} + \dots \\
    \ln \mu &amp;= \ln w + \beta_{0} + \beta_{1} \cdot X_{1} + \dots \\
\end{aligned}
\]</div>
<p>The exposure term is known as an <strong>Offset</strong>. It is a variable that is added to the model with a <strong>fixed coefficient of 1</strong>, representing a known relationship with the target variable.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Consider the following example for different exposures:</p>
<p><center></p>
<table>
<thead>
<tr>
<th align="center"><strong>Subject</strong></th>
<th align="center"><strong>Number of A's (Count)</strong></th>
<th align="center"><strong>Number of Students (Exposure)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">Math</td>
<td align="center">5</td>
<td align="center">10</td>
</tr>
<tr>
<td align="center">Science</td>
<td align="center">8</td>
<td align="center">20</td>
</tr>
<tr>
<td align="center">History</td>
<td align="center">10</td>
<td align="center">30</td>
</tr>
</tbody>
</table>
<p></center></p>
<p>It is not fair to directly compare the number of A's for each subject and conclude which is doing best - we should consider the <strong>underlying exposure</strong> as well to consider the A-rate.</p>
</div>
<p>The poisson coefficients have a very similar intepretation with the logit model - it represents the <strong>multiplicative increase</strong> in the count given a one unit increase or in the presence of another variable.</p>
<h3 id="dispersion_1"><strong>Dispersion</strong><a class="headerlink" href="#dispersion_1" title="Permanent link">&para;</a></h3>
<p>Although the poisson distribution is suited to model counts, it has a <strong>restrictive</strong> property where the <strong>mean and variance MUST be equal</strong>. This makes it inadequate where the underlying data exhibits <strong>overdispersion</strong>. As mentioned previously, one method is to adjust the re-scale the variance using the pearson residuals. This section addresses more drastic approaches to deal with it.</p>
<h4 id="negative-binomial"><strong>Negative Binomial</strong><a class="headerlink" href="#negative-binomial" title="Permanent link">&para;</a></h4>
<p>Another method is to use a different distribution which does not have this restrictive property - such as the  <strong>Negative Binomial Distribution</strong>:</p>
<ol>
<li>It has <strong>two parameters</strong> to fit the data, allowing for more flexibility</li>
<li>Poisson is a <strong>limiting case</strong> of the negative binomial (<strong>reasonable change</strong>)</li>
<li>Negative Binomial is a <strong>mixture of Poisson and Gamma</strong> (thus is a reasonable distribution)</li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the Negative Binomial is more flexible, why isnt the negative binomial used directly in the first place? Because Poisson is much <strong>simpler to model and interpret</strong>, with only parameter.</p>
</div>
<h4 id="zero-inflated"><strong>Zero Inflated</strong><a class="headerlink" href="#zero-inflated" title="Permanent link">&para;</a></h4>
<p>A common reason for Over-dispersion is due to an <strong>excess of zeroes</strong> in reality compared to our expectation, known as <strong>Zero Inflation</strong>. In these cases, the original distribution must be <strong>adjusted to account for probability of zeroes</strong> occuring.</p>
<p>A <strong>Zero Inflated Model</strong> is appropriate when the underlying <strong>event occurred, but no count was made</strong>. For instance, a policyholder might choose not to make a claim despite incurring a loss due to considering premium rate increases.</p>
<p>Thus, it is necessary to account for and <strong>distinguish between the types</strong> of zeroes. This can be done via a <strong>Logistic Regression</strong> which is set to identify <strong>False Zeroes</strong>:</p>
<ul>
<li>False Zeroes (EG. Policyholders who incurred a loss but did not report)</li>
<li>True Zeroes (EG. Policyholders who did not incur a loss)</li>
</ul>
<p>Thus, mixing the Poisson and the Logistic Regression output, the PMF of the <strong>mixture</strong> can be constructed:</p>
<ul>
<li><strong>Logistic</strong> - Identify observations with false zeroes</li>
<li><strong>Poisson</strong> - Underlying data generating process (assuming no false)</li>
</ul>
<div class="arithmatex">\[
\begin{aligned}
    \text{Mixture PMF}
    &amp;= \begin{cases}
        \pi + (1 - \pi) \cdot P(Y = 0) ,&amp;Y = 0 \\
        (1 - \pi) \cdot P(Y \gt 0) ,&amp;Y \gt 0
    \end{cases}
\end{aligned}
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The key idea is that the original probabilities are adjusted to account for the possibility of being False Zeroes.</p>
</div>
<h4 id="hurdle-model"><strong>Hurdle Model</strong><a class="headerlink" href="#hurdle-model" title="Permanent link">&para;</a></h4>
<p>A <strong>Hurdle Model</strong> is appropriate when the zeroes occur because a certain <strong>hurdle or threshold was not crossed</strong>. For instance, when projecting the number of laps swam based on the number of people who visited the swimming pool, it should account for individuals who <strong>never entered</strong> the pool (Hurdle) (EG. Parents).</p>
<p>In this case, there is a clear reason for the zeroes, thus the probability for the zero count should be <strong>modelled seperate</strong> for the non-zero values:</p>
<ul>
<li><strong>Logistic</strong> - Identify observations that do NOT cross the threshold (<span class="arithmatex">\(\pi\)</span>)</li>
<li><strong>Poisson</strong> - Underlying data generating process (assuming all cross)</li>
</ul>
<div class="arithmatex">\[
\begin{aligned}
    \text{Mixture PMF}
    &amp;= \begin{cases}
        \pi ,&amp;Y = 0 \\
        (1 - \pi) \cdot \frac{P(Y \gt 0)}{1 - P(Y =0)} ,&amp;Y \gt 0
    \end{cases}
\end{aligned}
\]</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The resulting distribution should use a <strong>zero-truncated</strong> probability to reflect that the original distribution should not be used for zero counts.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Although not shown explicitly, Hurdle models are the only <strong>one of two models</strong> discussed in this section that allows for UNDER-dispersion as well; the other is the Latent Class Model.</p>
</div>
<h3 id="heterogeneity-model"><strong>Heterogeneity Model</strong><a class="headerlink" href="#heterogeneity-model" title="Permanent link">&para;</a></h3>
<p>A <strong>Heterogeneity Model</strong> is where one or more of the model parameters are <strong>modelled as a seperate distribution</strong>, known as the <strong>Heterogeneity Component</strong>. The resulting distribution is mixture as well:</p>
<ul>
<li>Poisson &amp; Log-Gamma</li>
<li>Poisson &amp; Lognormal</li>
</ul>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>The word Heterogeneity means <strong>Diversity</strong>.</p>
<p>In essence, Heterogeneity models <strong>account for the diversity</strong> in the data that is <strong>NOT observed</strong> but still significantly impact the target variable. </p>
</div>
<h4 id="latent-class-models"><strong>Latent Class Models</strong><a class="headerlink" href="#latent-class-models" title="Permanent link">&para;</a></h4>
<p>A <strong>Latent Class Model</strong> is where the modeller would like to split the data into classes:</p>
<ul>
<li>Healthy vs Ill People</li>
<li>Low vs High Risk individuals</li>
</ul>
<p>These classes are "unobserved" (<strong>Latent</strong>) in the data as they are <strong>not explicit</strong>. Thus, the classes are treated as a <strong>Discrete Random Variable</strong> and modelled via a <strong>Mixture</strong> as well.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Latent Class Models can be said to be modelling the heterogeneity described in the previous section as well.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Although not shown explicitly, Latent Class models are the only <strong>one of two models</strong> discussed in this section that allows for UNDER-dispersion as well; the other is the <strong>Hurdle Model</strong>.</p>
</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../5.%20Model%20Selection/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Model Selection" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Model Selection
            </div>
          </div>
        </a>
      
      
        
        <a href="../7.%20Tree%20Models/" class="md-footer__link md-footer__link--next" aria-label="Next: Tree Models" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Tree Models
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.16e2a7d4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.5a2dcb6a.min.js"></script>
      
        <script src="../../../config/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
    
  </body>
</html>