# **Multi State Models**

## **Overview**

In FAM-L, we only considered simple contracts that paid a benefit upon the death or survival of the policyholder. In reality, more complicated contracts exist:

* Paying a stream of benefits while the policyholder is stricken with disease
* Paying a benefit upon death of the policyholder

!!! Info

    The above example is known as **Disability Income** insurance.

To effectively analyze these more complicated contracts, the survival model must be reformulated into a **Multi-State Model**.

## **States**

**States** are a set of **distinct values** that the system can be in.

In the context of a simple assurance or annuity, the policyholder is either **Alive** or **Dead**, resulting in a **two-state model**:

<!-- Obtained from ALTAM Textbook -->
![AliveDead](Assets/3.%20Multi%20State%20Models.md/AliveDead.png){.center}

In the context of the disability income insurance described earlier, a policyholder could either be **Healthy**, **Sick** or **Dead**:

<!-- Obtained from ALTAM Textbook -->
![SicknessDeath](Assets/3.%20Multi%20State%20Models.md/SicknessDeath.png){.center}

!!! Note

    Notice that this is an extension of the Alive-Dead model, where the Alive state is further broken down into Healthy or Sick.

The state of the system is measured at **different points in time**. The goal is to model how the system **transitions** across various states over time **via probability**.

* **Discrete Process**: Countable number of time points
* **Continuous Process**: Uncountable number of time points

When moving from one time to another, there are two possible events that can occur:

* System **transitions** into another state
* System **remains** in the same state

Let $Y_{t}$ be the **random variable** denoting the state of the system at time $t$. Thus, the **transition probabilities** can be denoted as follows:

<center>

| Transition | Remain |
| :-: | :-: |
| Probability of transition from $i$ to $j$ | Probability of remaining in state $i$ |
| $P \left(Y_{x+t} = j \mid Y_{x} = i \right)$ | $P \left(Y_{x+t} = i, \text{for all t} \mid Y_{x} = i \right)$ |
| ${}_{t}p^{ij}_{x}$ | ${}_{t}p^{\bar{ii}}_{x}$ |

</center>

!!! Note

    Within actuarial notation, $i$ is commonly referred to as the **Departing State** while $j$ is referred to as the **Arriving State**.

!!! Tip

    The two have the following relationship:

    $$
    \begin{aligned}
        {}_{t}p^{\bar{ii}}_{x} \le {}_{t}p^{ii}_{x}       
    \end{aligned}
    $$

    This is due to the **definition** of the two probabilities, making the LHS a subset of the RHS:

    * **LHS**: Must **stay** in state $i$
    * **RHS**: Stay in state $i$ OR **transition out and back** to state $i$ by time t

    The key is to understand that **any number of transitions** could have actually occurred between the $x$ and $x+t$ - the probability is only concerned with the departing and arriving state.

It is typically assumed that the process also exhibits the **Markov Property** - that the probability of transition at any point is **independent** of the history of the process. The only factor affecting the probability is the **current state** of the system.

$$
    P(Y_{t+1} = i \mid Y_{t} = j, Y_{t-1} = k, \dots) = P(Y_{t+1} = i \mid Y_{t} = j)
$$

!!! Info

    This is conceptually similar to the **Memoryless Property** of the exponential distribution.

## **Discrete Multi State Models**

A discrete multi state model that follows the markov property is known as a **Markov Chain**.

### **One Period Transitions**

Consider a model with $n$ distinct states. The **ONE-period transition probabilities** for each state to every other state can be summarized into a **Transition Matrix**:

$$
\begin{aligned}
    \boldsymbol{P}_{x}
    &= \begin{pmatrix}
            p_{x}^{00} & p_{x}^{01} & \dots & p_{x}^{0n} \\
            p_{x}^{10} & p_{x}^{11} & \dots & p_{x}^{1n} \\
            \vdots & & \ddots \\
            p_{x}^{n0} & p_{x}^{n1} & \dots & p_{x}^{nn}
        \end{pmatrix}
\end{aligned}
$$

There are a few key properties about the matrix:

* Since there are $n$ distinct states, the dimensions of the matrix are $n$ by $n$
* Each **row** represents a unique departing state ($i$)
* Each **column** represents a unique arriving state ($j$)

!!! Tip

    Notice that the probabilities along the **same row** represent **all possible transitions** from that particular departing state.

    Thus, the probabilities in each row MUST add up to 1:

    $$
        p_{x}^{00} + p_{x}^{01} + \dots + p_{x}^{0n} = 1
    $$

!!! Warning

    The transition matrix captures **ALL combinations** of state transitions, not just what is *possible*.

    Thus, it is not uncommon for these matrices to have a **large chunk of 0s**, as some state transitions are impossible.

    In particular, if transitioning out of a state is impossible ($p_{x}^{nn} = 1$), then the state is known as an **Absorbing State**. If not, it is known as a **Transient State**.

### **Multiple Period Transitions**

Similarly, we can consider the transition matrix over multiple periods:

$$
\begin{aligned}
    {}_{n}\boldsymbol{P}_{x}
    &= \begin{pmatrix}
            {}_{n}p_{x}^{00} & {}_{n}p_{x}^{01} & \dots & {}_{n}p_{x}^{0n} \\
            {}_{n}p_{x}^{10} & {}_{k}p_{x}^{11} & \dots & {}_{n}p_{x}^{1n} \\
            \vdots & & \ddots \\
            {}_{n}p_{x}^{n0} & {}_{n}p_{x}^{n1} & \dots & {}_{n}p_{x}^{nn}
        \end{pmatrix}
\end{aligned}
$$

It can be shown that this matrix is the **product of all the one-period transition matrices** that came before it:

$$
    {}_{n}\boldsymbol{P}_{x} = {}_{n}\boldsymbol{P}_{x} {}_{n}\boldsymbol{P}_{x+1} \dots {}_{n}\boldsymbol{P}_{x+k-1}
$$

!!! Tip

    The above uses **Matrix Multiplication**. The reverse "L" method can be used to quickly multiply matrices:

    <!-- Obtained from Wikipedia -->
    ![Matrix Multiplication](Assets/3.%20Multi%20State%20Models.md/Matrix%20Multiplication.png){.center}

!!! Warning

    A common mistake is thinking that since the matrices can be multiplied together, the individual probabilities can be directly multiplied as well.

    $$
        {}_{n}p^{00}_{x}
        \ne p^{00}_{x} \cdot p^{00}_{x+1} \dots p^{00}_{x+n-1}
    $$

    This logic does **NOT work** due to the nature of matrix multiplication. It does not account for the **possibility of transitioning to another state** but eventually transitioning back to state 0 by time $x+n$.

### **Chapman Kolmogorov Equation**

Matrix multiplication is a convenient way of summarizing ALL possible transitions. However, if only one transition is needed, it is faster to **directly compute** it instead.

Consider the following three time points:

* Time $x$: System is in state $i$
* Time $x+n-1$: System can be in **ANY state** (denoted as state $k$)
* Time $x+n$: System is in state $j$

<!-- Self Made -->
![Chapman Kolmogorov General](Assets/3.%20Multi%20State%20Models.md/Chapman%20Kolmogorov%20General.png){.center}

By the **law of total probability**, the probability of transitioning from state $i$ to $j$ in $k$ periods is the **sumproduct** of:

1. The probability of transitioning from state $i$ to any state $k$ in $m-1$ periods
2. The probability of transitioning from any state $k$ to state $j$ in one period

$$
\begin{aligned}
    {}_{n}p^{ij}_{x}
    &= P(Y_{t+n} = j \mid Y_{t} = i) \\
    &= \sum P(Y_{t+n-1} = k \mid Y_{t} = i) 
        \cdot P(Y_{t+n} = j \mid Y_{t+n-1} = k, Y_{t} = i) \\
    &= \sum P(Y_{t+n-1} = k \mid Y_{t} = i) 
        \cdot P(Y_{t+n} = j \mid Y_{t+n-1} = k), \ \text{Memoryless} \\
    &= \sum {}_{n-1}p^{ik}_{x} \cdot p^{kj}_{x+n-1}
\end{aligned}
$$

This expression is known as the **Chapman-Kolmogorov Equation**. Notice that it is **recursive** - the $m-1$ component can be decomposed the same way, resulting in **all components being one-period transition probabilities**. 

!!! Note

    The example can be made the other way round as well:

    * State $i$ to state $k$ in one period
    * State $k$ to state $j$ in $n-1$ periods

    Both will lead to the same outcome via recursion.

To demonstrate this, consider the following two state system:

<!-- Self Made -->
![Chapman Kolmogorov Example](Assets/3.%20Multi%20State%20Models.md/Chapman%20Kolmogorov%20Example.png){.center}

Consider **all possible ways** to go from state 1 to state 2 in two periods:

* State 1 > State 1 > State 1
* State 1 > State 2 > State 2

$$
    {}_{2}p^{12}_{x}
    = p^{11}_{x} \cdot p^{12}_{x+1} + p^{12}_{x} \cdot p^{22}_{x+1} 
$$

!!! Warning

    It is a common mistake to forget that the **system can stay** in the current state.

## **Continuous Multi State Model**

As its name suggests, a continuous multi-state model allows for transitions at **any time**. It is commonly referred to as a **Continuous Markov Chain**.

Similar to before, rather than probabilities, we instead consider a **Transition Intensities**:

$$
    \mu^{ij}_{x}(t) = \frac{d}{dt} {}_{t}p^{ij}_{x}
$$

It is analagous to the force of mortality in the base survival model. It represents the "probability" of transitioning from state $i$ to state $j$ **instantly** at time $x+t$.

!!! Note

    This implicitly assumes that only **ONE transition** can occur in a small period of time.

### **Direct Method**

The **probability of staying in the same state** can thus be calculated as follows:

$$
    {}_{t}p^{\bar{ii}}_{x} = e^{- \int \mu^{i \tau}_{x}(t)}
$$

The force represents the combination of forces that would cause a transition out of state $i$:

$$
\begin{aligned}
    \mu^{i \tau}_{x}(t) 
    &= \sum_{j \ne i} \mu^{ij}_{x}(t) \\
    &= \mu^{12}_{x}(t) + \mu^{13}_{x}(t) + \dots + \mu^{1n}_{x}(t)
\end{aligned}
$$

!!! Note

    This is analagous to the survival probability calculated from the force of mortality in the base survival model.

The probability of transitioning can be understood as the combination of the following components:

1. System remains in the **same state** $i$ till some time $x+s$
2. At that time, the system **instantly transitions** into state $j$
3. System remains in the **same state** $j$ till time $x+t$

$$
    {}_{t}p^{ij}_{x}
    = \int {}_{s}p^{\bar{ii}}_{x} \cdot \mu^{ij}_{x}(s) \cdot {}_{t-s}p^{\bar{jj}}_{x+s}
$$

!!! Tip

    If the arriving state is absorbing, then the final component is always equal to 1. Thus, the expression can be simplified.

The above assumes that there is only one way of transitioning - **directly** from state $i$ to state $j$. If there are **multiple ways to transition**, additional complexity is required.

Consider the following three state model used for Permanent Disability:

<!-- Obtained from ALTAM textbook -->
![Perm Disability](Assets/3.%20Multi%20State%20Models.md/Perm%20Disability%20Model.png){.center}

There are **two ways** to transition from state 0 to state 2:

1. **Direct transition** from state 0 to 2 (State 0 > State 2)
2. **Indirect transition** via state 1 (State 0 > State 1 > State 2)

The problem is in the second component. While it may be possible to derive an expression via first principles, it is generally not worth the time to do so.

In such cases, the probability of transitioning is much better taken as the **complement** of the remaining direct transitions:

$$
\begin{aligned}
    {}_{t}p^{00}_{x} + {}_{t}p^{01}_{x} + {}_{t}p^{02}_{x} &= 1 \\
    {}_{t}p^{02}_{x} &= 1 - {}_{t}p^{00}_{x} - {}_{t}p^{01}_{x}
\end{aligned}
$$

### **Approximation Method**

Notice that in the previous section, we have implicitly assumed that the **system cannot transition back into a previous state**.

For such cases, a more complex method known as the **Kolmogorov's Forward Equation** is required. It is a **differential equation** that can solve for the probability of transition.

!!! Note

    Very loosely speaking, a differential equation is a method of using the derivatives of a function to solve for the original function itself.

The **first derivative** of the transition probability can be expressed as the following:

$$
    \frac{d}{dt} {}_{t}p^{ij}_{x}
    = \sum_{k \ne j} [{}_{t}p^{ik}_{x} \cdot \mu^{kj}_{x}(t) 
                        - {}_{t}p^{ij}_{x} \cdot \mu^{jk}_{x}(t)]
$$

Loosely speaking, the DE is trying to **approximate the change** in probability of moving from state $i$ to state $j$ as:

$$
\begin{aligned}
    \text{Change}
    &= \text{Net Probability of moving into state j} \\
    &= \text{P(Start in i, move INTO j)} - \text{P(Start in i, move OUT of j)}
\end{aligned}
$$

The differential equation can be solved via **Euler's Method**:

$$
\begin{aligned}
    \frac{d}{dt} {}_{t}p^{ij}_{x}
    &= \frac{{}_{t+h}p^{ij}_{x} - {}_{t}p^{ij}_{x}}{h}
    = \frac{{}_{t}p^{ij}_{x} - {}_{t-h}p^{ij}_{x}}{h} \\
    &= \dots
\end{aligned}
$$

!!! Tip

    Very loosely speaking, Euler's method approximates the first derivative by setting it equal to the **tangent of the graph** at that point. The key intuition is that it will repeat this process **iteratively**, until it converges on a solution.

    <!-- Obtained from Xaktly -->
    ![Euler_Method](Assets/3.%20Multi%20State%20Models.md/Euler_Method.png){.center}

    There are **two variations** of the method - Forward & Backward, depending on how the approximation is done:

    $$
        \text{First Derivative}
        = \frac{y_{x+h} - y_{x}}{h} = \frac{y_{x} - y_{x-h}}{h}
    $$

    Use the variation that is best suited to find the target outcome.

!!! Note

    The differential equation can technically be solved via **Linear Algebra** to provide an exact solution. However, **Boundary Conditions** of the DE are required - which are out of scope for this exam.

### **Continuous to Discrete**

If Euler's method is used, then the resulting continuous probabilities can be converted into **discrete probabilities** for a markov chain with time intervals of $h$:

$$
\begin{aligned}
    {}_{h}p^{ij}_{x} &= h \cdot \mu^{ij}_{x} \\
    {}_{h}p^{ii}_{x} &= 1 - h \cdot \mu^{i \tau}_{x}
\end{aligned}
$$

The **first component** follows the same intuition as the force of mortality approximation. The **second component** uses the same method, but is the complement of all possible transitions.

## **Insurance Applications**

Multi-state assurances and annuities are concpetually similar to their single decrement counterparts - Equivalence Principle, Continuous Discrete Approximation etc.

This section highlights the key differences in a multi-state context.

### **Assurances**

A **Multi-State Assurance** pays a benefit whenever the insured **transitions** into a particular state.

The actuarial value of such an assurance is denoted by $A^{ij}_{x}$, where $i$ is the **current state** of the insured and $j$ is the **state which triggers a payment**.

The key is understanding that *any* transition into the state will trigger the payout. Thus, **all possible transitions** into state must be considered at **each time** period.

!!! Warning

    It is a common mistake to assume that because there is **no direct** transition to the insured state, the value of the assurance must be 0.

    This is incorrect, as all possible transition pathways, **regardless of the number of steps required**, should be considered. 

Consider the following example:

* Mortality follows a **permanent disability model**
* Insured owns a **2 year discrete TERM assurance**
* Benefit payment at the end of the year upon transition into state 2
* Insured is currently in state 0 (Healthy)

<!-- Obtained from ALTAM textbook -->
![Perm Disability](Assets/3.%20Multi%20State%20Models.md/Perm%20Disability%20Model.png){.center}

$$
\begin{array}{|c|c|c|c|}
\hline
    \text{Time}
        & \text{Transition}
        & \text{Probability} 
        & \text{PV Benefit} \\
\hline
    1
        & \text{0 - 2}
        & p^{02}_{x}
        & Bv \\
\hline
    2
        & \text{0 - 0 - 2}
        & p^{00}_{x} \cdot p^{02}_{x+1}
        & Bv^2 \\
\hline
    2
        & \text{0 - 1 - 2}
        & p^{01}_{x} \cdot p^{12}_{x+1}
        & Bv^2 \\
\hline
\end{array}
$$

$$
\begin{aligned}
    A^{02}_{x\enclose{actuarial}{2}}
    &= p^{02}_{x} \cdot Bv + p^{00}_{x} p^{02}_{x+1} \cdot Bv^2 
    + p^{01}_{x} \cdot p^{12}_{x+1} \cdot Bv^2 \\
    &= p^{02}_{x} \cdot Bv 
    + (p^{00}_{x} p^{02}_{x+1} + p^{01}_{x} \cdot p^{12}_{x+1}) \cdot Bv^2 \\
    &= p^{02}_{x} \cdot Bv + {}_{2}p^{02}_{x} \cdot Bv^2
\end{aligned}
$$

!!! Warning

    The notation for a TA is **slightly different** from what is normally used. It does not make sense to include the "1" in the superscript as it is already being used by the state notation.

!!! Tip

    Notice that this is analagous to a regular term assurance:

    $$
        A^{1}_{x:\enclose{actuarial}{2}}
        = q_{x} \cdot Bv + {}_{2 \mid}q_{x} \cdot Bv 
    $$

    The key difference being that the probabilities under the multi state models can be **broken down into multiple cases** to account for multiple possible transitions.

Similarly, the relationship between Term and WL assurances remains true, with a slight modification to consider **ALL possible state changes**:

$$
\begin{aligned}
    A^{ij}_{x\enclose{actuarial}{n}}
    &= A^{ij}_{x} - v^{n} \sum {}_{n}p^{ik}_{x} A^{kj}_{x+n} \\
    &= A^{ij}_{x} - v^{n} {}_{n}p^{i0}_{x} A^{0j}_{x+n} - v^{n} {}_{n}p^{i1}_{x} A^{1j}_{x+n}x + \dots
\end{aligned}
$$

!!! Tip

    It may not be necessary to write every single transition probability as some may naturally evaluate to 0.

!!! Warning

    The survival probability is the probability of surviving to the **starting state** for the assurance at age $x+n$.

### **Annuities**

Conversely, a **Multi-State Annuity** pays a benefit whenever the insured **remains** in a particular state.

The actuarial value of such an assurance is denoted by $a^{ij}_{x}$, where $i$ is the **current state** of the insured and $j$ is the **state which triggers a payment**.

!!! Warning

    The general notation assumes that the insured is **NOT already in the state** that would trigger payment. For instance, an annuity that pays only while the insured is disabled.

    This is contrary to a life annuity, where the insured is already alive, and will receive payments for as long as they are alive.

Consider the following example:

* Mortality follows a **sickness death model**
* Insured owns a **2 year discrete temporary annuity**
* Benefit payment at the beginning of the year if they are in state 1
* Insured is currently in state 0 (Healthy)

### **Reserves**

Recall that reserves are calculated as the EPV of the net outflows each period. In a multi-state setting, the **outflows are dependent on the state** of the insured at the time of valuation. Thus, the reserve must reflect **two dimensions** - both time and state.

$$
    {}_{t}V^{(i)} = \text{EPV(Benefits)}_{t}^{i}
                  + \text{EPV(Expenses)}_{t}^{i}
                  - \text{EPV(Premiums)}_{t}^{i}
$$

!!! Tip

    Note that some terms may **naturally evaluate to 0**. For instance,

    * **Premiums may not be payable** while in that state
    * **Certain benefits may not payable** in that state

Reserves for a continuous assurance or annuity can be instead calculated using **Thiele's Differential Equation**:

$$
\begin{aligned}
    \frac{d}{dt} {}_{t}V^{i}
    &= \delta_{t} \cdot {}_{t}V^{i} + \left(B_{t}^{i} + e_{t}^{i} - P_{t}^{i} \right) \\
    &- \sum_{j \ne i} \mu^{ij}_{x}(t) \cdot (b^{ij} + {}_{t}V^{j} - {}_{t}V^{i})
\end{aligned}
$$

Similar to before, the DE is trying to **approximate the change in the reserve**:

* Earns **interest**
* Increases by the **rate** of net outflow
* **Release** to pay off any **lump sum benefits** on transition
* **Change in reserve** across states

!!! Warning

    Do NOT mix up the two benefit variables:

    * **Big B**: **Rate** of benefit payment **while in** the current state
    * **Small B**: **Lump Sum** benefit payment **upon transition** into other state

Similarly, the DE can be solved using **Euler's Method**:

$$
\begin{aligned}
    \frac{d}{dt} {}_{t}V^{i}
    &= \frac{{}_{t}V^{i} - {}_{t-h}V^{i}}{h}
    = \frac{{}_{t+h}V^{i} - {}_{t}V^{i}}{h} \\
    &= \dots
\end{aligned}
$$
