# **Multi State Models**

## **Overview**

In FAM-L, we only considered simple contracts that paid a benefit upon the death or survival of the policyholder. In reality, more complicated contracts exist:

* Paying a stream of benefits while the policyholder is stricken with disease
* Paying a benefit upon death of the policyholder

!!! Info

    The above example is known as **Disability Income** insurance.

To effectively analyze these more complicated contracts, the survival model must be reformulated into a **Multi-State Model**.

## **States**

**States** are a set of **distinct values** that the system can be in.

In the context of a simple assurance or annuity, the policyholder is either **Alive** or **Dead**, resulting in a **two-state model**:

<!-- Obtained from ALTAM Textbook -->
![AliveDead](Assets/3.%20Multi%20State%20Models.md/AliveDead.png){.center}

In the context of the disability income insurance described earlier, a policyholder could either be **Healthy**, **Sick** or **Dead**:

<!-- Obtained from ALTAM Textbook -->
![SicknessDeath](Assets/3.%20Multi%20State%20Models.md/SicknessDeath.png){.center}

!!! Note

    Notice that this is an extension of the Alive-Dead model, where the Alive state is further broken down into Healthy or Sick.

The state of the system is measured at **different points in time**. The goal is to model how the system **transitions** across various states over time **via probability**.

* **Discrete Process**: Countable number of time points
* **Continuous Process**: Uncountable number of time points

When moving from one time to another, there are two possible events that can occur:

* System **transitions** into another state
* System **remains** in the same state

Let $Y_{t}$ be the **random variable** denoting the state of the system at time $t$. Thus, the **transition probabilities** can be denoted as follows:

<center>

| Transition | Remain |
| :-: | :-: |
| Probability of transition from $i$ to $j$ | Probability of remaining in state $i$ |
| $P \left(Y_{x+t} = j \mid Y_{x} = i \right)$ | $P \left(Y_{x+t} = i, \text{for all t} \mid Y_{x} = i \right)$ |
| ${}_{t}p^{ij}_{x}$ | ${}_{t}p^{\bar{ii}}_{x}$ |

</center>

!!! Note

    Within actuarial notation, $i$ is commonly referred to as the **Departing State** while $j$ is referred to as the **Arriving State**.

!!! Tip

    The two have the following relationship:

    $$
    \begin{aligned}
        {}_{t}p^{\bar{ii}}_{x} \le {}_{t}p^{ii}_{x}       
    \end{aligned}
    $$

    This is due to the **definition** of the two probabilities, making the LHS a subset of the RHS:

    * **LHS**: Must **stay** in state $i$
    * **RHS**: Stay in state $i$ OR **transition out and back** to state $i$ by time t

    The key is to understand that **any number of transitions** could have actually occurred between the $x$ and $x+t$ - the probability is only concerned with the departing and arriving state **at the specified times**.

It is typically assumed that the process also exhibits the **Markov Property** - that the probability of transition at any point is **independent** of the history of the process. The only factor affecting the probability is the **current state** of the system.

$$
    P(Y_{t+1} = i \mid Y_{t} = j, Y_{t-1} = k, \dots) = P(Y_{t+1} = i \mid Y_{t} = j)
$$

!!! Note

    This is conceptually similar to the **Memoryless Property** of the exponential distribution.

    In simple terms, the markov property assumes that incidence probability is the **same** for an entity that has **just entered** the state versus an entity that has **been in the state for a long time**.

## **Discrete Multi State Models**

A discrete multi state model that follows the markov property is known as a **Markov Chain**.

### **One Period Transitions**

Consider a model with $n$ distinct states. The **ONE-period transition probabilities** for each state to every other state can be summarized into a **Transition Matrix**:

$$
\begin{aligned}
    \boldsymbol{P}_{x}
    &= \begin{pmatrix}
            p_{x}^{00} & p_{x}^{01} & \dots & p_{x}^{0n} \\
            p_{x}^{10} & p_{x}^{11} & \dots & p_{x}^{1n} \\
            \vdots & & \ddots \\
            p_{x}^{n0} & p_{x}^{n1} & \dots & p_{x}^{nn}
        \end{pmatrix}
\end{aligned}
$$

There are a few key properties about the matrix:

* Since there are $n$ distinct states, the dimensions of the matrix are $n$ by $n$
* Each **row** represents a unique departing state ($i$)
* Each **column** represents a unique arriving state ($j$)

!!! Tip

    Notice that the probabilities along the **SAME ROW** represent **all possible transitions** from that particular departing state. Thus, the probabilities in each row MUST add up to 1:

    $$
        p_{x}^{00} + p_{x}^{01} + \dots + p_{x}^{0n} = 1
    $$

    Some questions might not provide the probabilities for all transitions, thus the above can be used to derive the missing probabilities.

!!! Warning

    The transition matrix captures **ALL combinations** of state transitions, not just what is *possible*. Thus, it is not uncommon for these matrices to have a **large chunk of 0s**, as some state transitions are impossible.

    In particular, if transitioning out of a state is impossible ($p_{x}^{nn} = 1$), then the state is known as an **Absorbing State**. If not, it is known as a **Transient State**.

    Based on the description, some states should **automatically be assumed to be absorbing** (EG. Death). Questions may not specify the transition probabilities for these states as it **should be understood** that the probabilities of transitioning out of the state must be 0.

### **Multiple Period Transitions**

Similarly, we can consider the transition matrix over multiple periods:

$$
\begin{aligned}
    {}_{n}\boldsymbol{P}_{x}
    &= \begin{pmatrix}
            {}_{n}p_{x}^{00} & {}_{n}p_{x}^{01} & \dots & {}_{n}p_{x}^{0n} \\
            {}_{n}p_{x}^{10} & {}_{k}p_{x}^{11} & \dots & {}_{n}p_{x}^{1n} \\
            \vdots & & \ddots \\
            {}_{n}p_{x}^{n0} & {}_{n}p_{x}^{n1} & \dots & {}_{n}p_{x}^{nn}
        \end{pmatrix}
\end{aligned}
$$

It can be shown that this matrix is the **product of all the one-period transition matrices** that came before it:

$$
    {}_{n}\boldsymbol{P}_{x} = {}_{n}\boldsymbol{P}_{x} {}_{n}\boldsymbol{P}_{x+1} \dots {}_{n}\boldsymbol{P}_{x+k-1}
$$

!!! Tip

    The above uses **Matrix Multiplication**. The reverse "L" method can be used to quickly multiply matrices:

    <!-- Obtained from Wikipedia -->
    ![Matrix Multiplication](Assets/3.%20Multi%20State%20Models.md/Matrix%20Multiplication.png){.center}

!!! Warning

    A common mistake is thinking that since the matrices can be multiplied together, the individual probabilities can be directly multiplied as well.

    $$
        {}_{n}p^{00}_{x}
        \ne p^{00}_{x} \cdot p^{00}_{x+1} \dots p^{00}_{x+n-1}
    $$

    This logic does **NOT work** due to the nature of matrix multiplication. It does not account for the **possibility of transitioning to another state** but eventually transitioning back to state 0 by time $x+n$.

### **Chapman Kolmogorov Equation**

Matrix multiplication is a convenient way of summarizing ALL possible transitions. However, if only one transition is needed, it is faster to **directly compute** it instead.

Consider the following three time points:

* Time $x$: System is in state $i$
* Time $x+n-1$: System can be in **ANY state** (denoted as state $k$)
* Time $x+n$: System is in state $j$

<!-- Self Made -->
![Chapman Kolmogorov General](Assets/3.%20Multi%20State%20Models.md/Chapman%20Kolmogorov%20General.png){.center}

By the **law of total probability**, the probability of transitioning from state $i$ to $j$ in $k$ periods is the **sumproduct** of:

1. The probability of transitioning from state $i$ to any state $k$ in $m-1$ periods
2. The probability of transitioning from any state $k$ to state $j$ in one period

$$
\begin{aligned}
    {}_{n}p^{ij}_{x}
    &= P(Y_{t+n} = j \mid Y_{t} = i) \\
    &= \sum P(Y_{t+n-1} = k \mid Y_{t} = i) 
        \cdot P(Y_{t+n} = j \mid Y_{t+n-1} = k, Y_{t} = i) \\
    &= \sum P(Y_{t+n-1} = k \mid Y_{t} = i) 
        \cdot P(Y_{t+n} = j \mid Y_{t+n-1} = k), \ \text{Memoryless} \\
    &= \sum {}_{n-1}p^{ik}_{x} \cdot p^{kj}_{x+n-1}
\end{aligned}
$$

This expression is known as the **Chapman-Kolmogorov Equation**. Notice that it is **recursive** - the $m-1$ component can be decomposed the same way, resulting in **all components being one-period transition probabilities**. 

!!! Note

    The example can be made the other way round as well:

    * State $i$ to state $k$ in one period
    * State $k$ to state $j$ in $n-1$ periods

    Both will lead to the same outcome via recursion.

To demonstrate this, consider the following two state system:

<!-- Self Made -->
![Chapman Kolmogorov Example](Assets/3.%20Multi%20State%20Models.md/Chapman%20Kolmogorov%20Example.png){.center}

Consider **all possible ways** to go from state 1 to state 2 in two periods:

* State 1 > State 1 > State 1
* State 1 > State 2 > State 2

$$
    {}_{2}p^{12}_{x}
    = p^{11}_{x} \cdot p^{12}_{x+1} + p^{12}_{x} \cdot p^{22}_{x+1} 
$$

!!! Warning

    It is a common mistake to forget that the **system can stay** in the current state.

Similar to FAM-L, questions might provide a **starting population** and ask for Expectation, Variance or the probability of a specific number of survivors. In these cases, use the above multi-state calculations to determine the **probability of an individual** and apply it in the **Binomial Distribution** (assuming lives are independent) to determine the requested quantities.

## **Continuous Multi State Model**

As its name suggests, a continuous multi-state model allows for transitions at **any time**. It is commonly referred to as a **Continuous Markov Chain**.

Similar to before, rather than probabilities, we instead consider a **Transition Intensities**:

$$
    \mu^{ij}_{x}(t) = \frac{d}{dt} {}_{t}p^{ij}_{x}
$$

It is analagous to the force of mortality in the base survival model. It represents the "probability" of transitioning from state $i$ to state $j$ **instantly** at time $x+t$.

!!! Note

    This implicitly assumes that only **ONE transition** can occur in a small period of time.

### **Direct Method**

The **probability of staying in the same state** can thus be calculated as follows:

$$
    {}_{t}p^{\bar{ii}}_{x} = e^{- \int \mu^{i \tau}_{x}(t)}
$$

The force represents the combination of forces that would cause a transition out of state $i$:

$$
\begin{aligned}
    \mu^{i \tau}_{x}(t) 
    &= \sum_{j \ne i} \mu^{ij}_{x}(t) \\
    &= \mu^{12}_{x}(t) + \mu^{13}_{x}(t) + \dots + \mu^{1n}_{x}(t)
\end{aligned}
$$

!!! Tip

    Similar to FAM-L, if the force of transition is constant, then the result will simplify to:

    $$
        {}_{t}p^{\bar{ii}}_{x} = e^{- \mu^{i \tau}_{x}(t) \cdot t}
    $$

In a continuous setting, it is not possible to know the *exactly* when a transition will occur. Thus, the probability involves three components:

1. Staying in the **same state** till some time $s$
2. Instantly **transitioning to the target state** at time $s$
3. Staying in the target state for the remainder of time $t-s$ 

$$
    {}_{t}p^{ij}_{x}
    = \int^{t}_{0} {}_{s}p^{\bar{ii}}_{x} \cdot \mu^{ij}_{x}(s) \cdot {}_{t-s}p^{\bar{jj}}_{x+s}
$$

It is also possible to determine the probability of a situation whereby after transitioning, the system **does NOT stay in the same state**:

$$
    \text{Prob} = \int^{t}_{0} {}_{s}p^{\bar{ii}}_{x} \cdot \mu^{ij}_{x}(s) \cdot (1 - {}_{t-s}p^{\bar{jj}}_{x+s})
$$

!!! Tip

    The above assumes that there is only **ONE WAY** of transitioning - **directly** from state $i$ to state $j$. If there are **multiple ways to transition**, it may be easier to take another approach.


    <!-- Obtained from ALTAM textbook -->
    ![Perm Disability](Assets/3.%20Multi%20State%20Models.md/Perm%20Disability%20Model.png){.center}

    There are **two ways** to transition from state 0 to state 2:

    1. **Direct transition** from state 0 to 2 (State 0 > State 2)
    2. **Indirect transition** via state 1 (State 0 > State 1 > State 2)

    The problem is in the second component. While it may be possible to derive an expression via first principles, it is generally not worth the time to do so. It easier to take the **complement** of the remaining direct transitions:

    $$
    \begin{aligned}
        {}_{t}p^{00}_{x} + {}_{t}p^{01}_{x} + {}_{t}p^{02}_{x} &= 1 \\
        {}_{t}p^{02}_{x} &= 1 - {}_{t}p^{00}_{x} - {}_{t}p^{01}_{x}
    \end{aligned}
    $$

### **Kolmogorov Equation**

Notice that in the previous section, we have implicitly assumed that the **system cannot transition back into a previous state**. For such cases, a more complex method known as the **Kolmogorov's Forward Equation** is required. It is a **differential equation** that can solve for the probability of transition.

!!! Note

    Very loosely speaking, a differential equation is a method of using the derivatives of a function to solve for the original function itself.

Loosely speaking, the **first derivative of the probability** is the **change** in probability of moving from state $i$ to state $j$:

$$
\begin{aligned}
    \frac{d}{dt} {}_{t}p^{ij}_{x}
    &= \text{P(Start in i, move INTO j)} - \text{P(Start in i, move OUT of j)} \\
    &= \sum_{k \ne j} {}_{t}p^{ik}_{x} \cdot \mu^{kj}_{x}(t) - \sum_{k \ne j} {}_{t}p^{ij}_{x} \cdot \mu^{jk}_{x}(t)
\end{aligned}
$$ 

!!! Note

    If the target state is absorbing, then it is impossible to move out from that state. Hence, the second component would be **0**.

If solved using **Linear Algebra** or if the value of the derivative is **provided**, the kolmogorov equations provide an **exact solution**. However, that is **out of scope** for the purposes of the exam. Instead, the equation can be **approximately** solved using **Euler's Method**:

$$
\begin{aligned}
    \frac{d}{dt} {}_{t}p^{ij}_{x}
    &= \sum_{k \ne j} [{}_{t}p^{ik}_{x} \cdot \mu^{kj}_{x}(t) - {}_{t}p^{ij}_{x} \cdot \mu^{jk}_{x}(t)] \\
    \frac{{}_{t+h}p^{ij}_{x} - {}_{t}p^{ij}_{x}}{h}
    &= \sum_{k \ne j} [{}_{t}p^{ik}_{x} \cdot \mu^{kj}_{x}(t) - {}_{t}p^{ij}_{x} \cdot \mu^{jk}_{x}(t)] \\
    {}_{t+h}p^{ij}_{x}
    &= {}_{t}p^{ij}_{x}
    + h \cdot \sum_{k \ne j} [{}_{t}p^{ik}_{x} \cdot \mu^{kj}_{x}(t) - {}_{t}p^{ij}_{x} \cdot \mu^{jk}_{x}(t)]
\end{aligned}
$$

!!! Note

    Very loosely speaking, Euler's method **approximates** the first derivative by setting it equal to the **tangent of the graph** at that point. The key intuition is that it will repeat this process **iteratively**, until it converges on a solution.

    <!-- Obtained from Xaktly -->
    ![Euler_Method](Assets/3.%20Multi%20State%20Models.md/Euler_Method.png){.center}

    Note that if a step size is not provided, it means that the question likely does not expect Euler's method to be used; there should be another method to sovle the equation based on the information given.

!!! Tip

    There are two variations of the method:

    $$
    \begin{aligned}
        \text{Forward Method} &= \frac{{}_{t+h}p - {}_{t}p}{h} \\
        \text{Backward Method} &= \frac{{}_{t}p - {}_{t-h}p}{h}
    \end{aligned}
    $$

    Notice that the main equation uses ${}_{t}p$ - the choice of the above method will determine what the value of $t$ will be.  Use the **variation that is best suited** for the situation based on the given information. For kolmogorov's equation, the **forward method** is typically used.

The step size $h$ is usually **defined by the question**. It affects the **number of iterations** needed to solve the question. Consider the following model:

<!-- Obtained from Coaching Actuaries -->
![Kolmogorov_Example](Assets/3.%20Multi%20State%20Models.md/Kolmogorov_Example.png){.center}

$$
\begin{aligned}
    \text{Objective} &= {}_{1}p^{10}_{x} \\
    \text{Step Size} &= \frac{1}{2} \\
    \\
    \therefore {}_{1}p^{10}_{x}
    &= {}_{0.5}p^{10} + 0.5 [{}_{0.5}p^{11}_{x} \mu^{10}_{x}(t)
        - {}_{0.5}p^{10}_{x} \mu^{01}_{x}(t)] \\
    \\
    {}_{0.5}p^{10}
    &= {}_{0}p^{10}_{x} + 0.5 [{}_{0}p^{11}_{x} \mu^{10}_{x}(t)
        - {}_{0}p^{10}_{x} \mu^{01}_{x}(t)] \\
    {}_{0.5}p^{11}
    &= {}_{0}p^{11}_{x} + 0.5 \left [{}_{0}p^{10}_{x} \mu^{01}_{x}(t)
        - {}_{0}p^{10}_{x} \left(\mu^{10}_{x}(t) + \mu^{12}_{x}(t) \right) \right]
\end{aligned}
$$

The equation can be solved because the following two items can always be simplified:

* ${}_{0}p^{10}_{x} = 0$: System **cant** be in two states at the same time
* ${}_{0}p^{11}_{x} = 1$: System **must** be in that state at the current time

The above are known as the **boundary conditions** of the DE. Loosely speaking, they are **constraints** that must exist in order for the DE to be solved. If the equation is solving for ${}_{t}p^{ij}_{x}$, then the associated boundary condition is ${}_{0}p^{ij}_{x}$.

!!! Tip

    These questions typically require **multiple recursions** of the equation to a point where one of the values are **known** - either through the above **boundary conditions** or a **value provided** by the question.
    
    It is recommended to start from the boundary condition and roll forward the equation to avoid excessive notation. 

    If the **step size is equal to the specified duration**, the probability can be solved in one step because it will recurse to time 0, where the boundary conditions can be used.

Notice that the two kolmogorov equations (Discrete & Continuous) follow the same intuition - transitioning to some intermediate state before reaching the final state.

### **Continuous to Discrete**

Using Euler's Method, it can be shown that a **discrete markov chain** with intervals of $h$ can be used to approximate the kolmogorov equation as well:

$$
\begin{aligned}
    {}_{t+h}p^{11}_{x}
    &= {}_{t}p^{11}_{x} {}_{h}p^{11}_{x+t} + {}_{t}p^{10}_{x} {}_{h}p^{01}_{x+t}
    \\
    {}_{t+h}p^{11}_{x}
    &= {}_{t}p^{11}_{x} (1 - {}_{h}p^{10}_{x+t} + {}_{h}p^{12}_{x+t}) + {}_{t}p^{10}_{x} {}_{h}p^{01}_{x+t}
    \\
    {}_{t+h}p^{11}_{x}
    &= {}_{t}p^{11}_{x} - {}_{t}p^{11}_{x} ({}_{h}p^{10}_{x+t} + {}_{h}p^{12}_{x+t}) + {}_{t}p^{10}_{x} {}_{h}p^{01}_{x+t} \\
    {}_{t+h}p^{11}_{x} - {}_{t}p^{11}_{x}
    &= {}_{t}p^{10}_{x} {}_{h}p^{01}_{x+t} - {}_{t}p^{11}_{x} ({}_{h}p^{10}_{x+t} + {}_{h}p^{12}_{x+t})
    \\
    \frac{{}_{t+h}p^{11}_{x} - {}_{t}p^{11}_{x}}{h}
    &= {}_{t}p^{10}_{x} \frac{{}_{h}p^{01}_{x+t}}{h}
    - {}_{t}p^{11}_{x} \left(\frac{{}_{h}p^{10}_{x+t}}{h} + \frac{{}_{h}p^{12}_{x+t}}{h} \right)
    \\
    \lim \left[\frac{{}_{t+h}p^{11}_{x} - {}_{t}p^{11}_{x}}{h} \right]
    &= \lim \left[{}_{t}p^{10}_{x} \frac{{}_{h}p^{01}_{x+t}}{h}
    - {}_{t}p^{11}_{x} \left(\frac{{}_{h}p^{10}_{x+t}}{h} + \frac{{}_{h}p^{12}_{x+t}}{h} \right) \right]
    \\
    \frac{d}{dt} {}_{t}p^{11}_{x}
    &= {}_{t}p^{10}_{x} \mu^{11}_{x}(t) - {}_{t}p^{11}_{x} [\mu^{10}_{x}(t) + \mu^{12}_{x}(t)]
\end{aligned}
$$

!!! Note

    The key portion of the proof is the derivation of the force of transition. The intuition can be found in this section of FAM-L.

The probabilities for the markov chain can be approximated using the following:

$$
\begin{aligned}
    {}_{h}p^{ij}_{x} &= h \cdot \mu^{ij}_{x}(t) \\
    {}_{h}p^{ii}_{x} &= 1 - h \cdot \mu^{i \tau}_{x}(t)
\end{aligned}
$$

!!! Note

    Both are based on the same intuition as the force of mortality approximation from FAM-L, which will come naturally if the derivation is understood. Thus, similarly, a **smaller step size** will lead to a **more accurate** approximation.

Using the same example as before:

$$
\begin{aligned}
    \text{Pathway 1} &: 1 - 1 - 0 \\
    \text{Pathway 2} &: 1 - 0 - 0 \\
    \\
    \therefore {}_{1}p^{10}_{x}
    &= {}_{0.5}p^{11}_{x} \cdot {}_{0.5}p^{10}_{x+0.5} + {}_{0.5}p^{10}_{x} \cdot {}_{0.5}p^{00}_{x+0.5} 
\end{aligned}
$$

!!! Tip

    One constraint with this method is whether or not the force of transition at the intemediate ages (EG. $x+0.5$) are provided. However, if the force of transition is constant, then the **same force** can be used for all ages.

## **Insurance Applications**

Multi-state assurances and annuities are concpetually similar to their single decrement counterparts - Equivalence Principle, Continuous Discrete Approximation etc.

This section highlights the key differences in a multi-state context.

### **Multi State Assurances**

A **Multi-State Assurance** pays a benefit whenever the insured **transitions** into a particular state. The actuarial value of such an assurance is denoted by $A^{ij}_{x}$, where $i$ is the **current state** of the insured and $j$ is the **state which triggers a payment**.

The key is understanding that *any* transition into the state will trigger the payout. Thus, **all possible transitions** into state must be considered at **each time** period.

!!! Warning

    It is a common mistake to assume that because there is **no direct** transition to the insured state, the value of the assurance must be 0.

    This is incorrect, as all possible transition pathways, **regardless of the number of steps required**, should be considered. 

Consider the following example:

* 2-year discrete term assurance
* Benefit payment at the end of the year **upon transition into state 2**
* Insured is currently in state 0

<!-- Obtained from ALTAM textbook -->
![Perm Disability](Assets/3.%20Multi%20State%20Models.md/Perm%20Disability%20Model.png){.center}

$$
\begin{array}{|c|c|c|c|}
\hline
    \text{Policy Year End }
        & \text{State}
        & \text{Probability} 
        & \text{PV Benefit} \\
\hline
    0
        & \text{0}
        & -
        & - \\
\hline
    1
        & \text{0 - 0}
        & p^{\bar{00}}_{x}
        & 0 \\
\hline
    1
        & \text{0 - 1}
        & p^{01}_{x}
        & 0 \\
\hline
    1
        & \text{0 - 2}
        & p^{02}_{x}
        & Bv \\
\hline
    2
        & \text{0 - 0 - 0}
        & p^{\bar{00}}_{x} \cdot p^{\bar{00}}_{x+1}
        & 0 \\
\hline
    2
        & \text{0 - 0 - 1}
        & p^{\bar{00}}_{x} \cdot p^{01}_{x+1}
        & 0 \\
\hline
    2
        & \text{0 - 0 - 2}
        & p^{\bar{00}}_{x} \cdot p^{02}_{x+1}
        & Bv^2 \\
\hline
    2
        & \text{0 - 1 - 1}
        & p^{01}_{x} \cdot p^{\bar{11}}_{x+1}
        & 0 \\
\hline
    2
        & \text{0 - 1 - 2}
        & p^{01}_{x} \cdot p^{12}_{x+1}
        & Bv^2 \\
\hline
    2
        & \text{0 - 2 - 2}
        & p^{02}_{x} \cdot p^{\bar{22}}_{x+1}
        & 0 \\
\hline
\end{array}
$$

!!! Warning

    It is a common mistake to assume that the last case of 0 - 2 - 2 should have a benefit listed there as the insured is in state 2 at the end of the year. However, the benefit is only payable if the insured transitions **INTO state 2 from some OTHER state**.  

$$
\begin{aligned}
    A^{02}_{x\enclose{actuarial}{2}}
    &= p^{02}_{x} \cdot Bv + p^{00}_{x} p^{02}_{x+1} \cdot Bv^2 
    + p^{01}_{x} \cdot p^{12}_{x+1} \cdot Bv^2 \\
    &= p^{02}_{x} \cdot Bv 
    + (p^{00}_{x} p^{02}_{x+1} + p^{01}_{x} \cdot p^{12}_{x+1}) \cdot Bv^2 \\
    &= p^{02}_{x} \cdot Bv + {}_{2}p^{02}_{x} \cdot Bv^2 \\
\end{aligned}
$$

!!! Warning

    The notation for a TA is **slightly different** from what is normally used. It does not make sense to include the "1" in the superscript as it is already being used by the state notation.

The key difference from FAM-L is that there are **multiple transitions** that could lead to a payout, not just death. Thus, it can be more generally expressed as:

$$
\begin{aligned}
    A^{ij}_{x}
    &= \sum^{\infty}_{t=0} \sum_{i \ne k} v^{t} {}_{t}p^{ik}_{x} \\
    \bar{A}^{ij}_{x}
    &= \int^{\infty}_{0} e^{-\delta t} \sum_{k \ne j} {}_{t}p^{ik}_{x} \mu^{kj}_{x+t}
\end{aligned}
$$

Similarly, the relationship between Term and WL assurances remains true, with a slight modification to consider **ALL possible state changes**:

$$
    A^{ij}_{x\enclose{actuarial}{n}}
    = A^{ij}_{x} - v^{n} \sum_{k \ne j} {}_{n}p^{ik}_{x} A^{kj}_{x+n}
$$

The key idea is that at the valuation time, the life is known to be in state $i$. However, in $n$ years time, the insured **could be in any state**, INCLUDING the target state. **ALL the possibilities** must be accounted for.

!!! Tip

    The same relationship holds for multi-state temporary and deferred annuities as well.

### **Multi State Annuities**

Conversely, a **Multi-State Annuity** pays a benefit whenever the insured is **in a particular state**. The actuarial value is denoted by $\ddot{a}^{ij}_{x}$, where $i$ is the **current state** of the insured and $j$ is the **state which triggers a payment**.

!!! Note

    The annuity will pay even for re-entries into state $j$. Consider the following scenario:

    * At time 2, the life transition into state $j$
    * At time 4, the life transitions into state $k$
    * At time 6, the life transitions back into state $j$ and remains there



    The above annuity will make a payment for **all times that the life is state $j$**; from time 2 to 4 as well as after time 6.

!!! Warning

    The general notation assumes that the insured is **NOT already in the state** that would trigger payment. For instance, an annuity that pays only while the insured is disabled.

    This is is **contrary** to the typical life annuity that was covered, where the insured is already alive, and will receive payments for as long as they are alive.

Consider the following example:

* 3-year Discrete Temporary Annuity
* Benefit payable at the beginning of the year **while in state 1**
* Insured is currently in state 0

<!-- Obtained from ALTAM textbook -->
![Perm Disability](Assets/3.%20Multi%20State%20Models.md/Perm%20Disability%20Model.png){.center}

$$
\begin{array}{|c|c|c|c|}
\hline
    \text{Policy Year End}
        & \text{State}
        & \text{Probability} 
        & \text{PV Benefit} \\
\hline
    0
        & \text{0}
        & -
        & - \\
\hline
    1
        & \text{0 - 0}
        & p^{\bar{00}}_{x}
        & 0 \\
\hline
    1
        & \text{0 - 1}
        & p^{01}_{x}
        & Bv \\
\hline
    1
        & \text{0 - 2}
        & p^{02}_{x}
        & 0 \\
\hline
    2
        & \text{0 - 0 - 0}
        & p^{\bar{00}}_{x} \cdot p^{\bar{00}}_{x+1}
        & 0 \\
\hline
    2
        & \text{0 - 0 - 1}
        & p^{\bar{00}}_{x} \cdot p^{01}_{x+1}
        & Bv^{2} \\
\hline
    2
        & \text{0 - 0 - 2}
        & p^{\bar{00}}_{x} \cdot p^{02}_{x+1}
        & 0 \\
\hline
    2
        & \text{0 - 1 - 1}
        & p^{01}_{x} \cdot p^{\bar{11}}_{x+1}
        & Bv^2 \\
\hline
    2
        & \text{0 - 1 - 2}
        & p^{01}_{x} \cdot p^{12}_{x+1}
        & 0 \\
\hline
    2
        & \text{0 - 2 - 2}
        & p^{02}_{x} \cdot p^{\bar{22}}_{x+1}
        & 0 \\
\hline
\end{array}
$$

!!! Tip

    Even though the policy term is 3 years, there is **no need** to consider what happens at the end of the third policy year as the benefits are payable at the **start of the year** - the last benefit is paid at the beginning of the third year (end of the second year).

$$
\begin{aligned}
    \ddot{a}^{01}_{x\enclose{actuarial}{3}}
    &= p^{01}_{x} \cdot Bv
    + p^{\bar{00}}_{x} \cdot p^{01}_{x+1} \cdot Bv^{2} + p^{\bar{00}}_{x} \cdot p^{01}_{x+1} \cdot Bv^{2} \\
    &= p^{01}_{x} \cdot Bv + (p^{\bar{00}}_{x} \cdot p^{01}_{x+1} + p^{\bar{00}}_{x} \cdot p^{01}_{x+1}) \cdot Bv^{2} \\
    &= p^{01}_{x} \cdot Bv + {}_{2}p^{01}_{x} \cdot Bv^{2} \\
\end{aligned}
$$

!!! Note

    There is actually **no need to change the notation** for temporary annuiities as they did not require a superscript in the first place. However, it may be better to use the same notation in a multi-state setting to avoid confusion.

Similarly, annuities can be generally expressed as:

$$
\begin{aligned}
    \ddot{a}^{ij}_{x}
    &= \sum^{\infty}_{t=0} v^{t} {}_{t}p^{ij}_{x} \\
    \bar{a}^{ij}_{x}
    &= \int^{\infty}_{0} e^{-\delta t} {}_{t}p^{ij}_{x}
\end{aligned}
$$

#### **Relationships**

There is an **interesting relationship** among multi-state annuities. Consider the same 3-state model from before:

$$
\begin{aligned}
    {}_{t}p^{00}_{x} + {}_{t}p^{01}_{x} + {}_{t}p^{02}_{x} &= 1 \\
    {}_{t}p^{00}_{x} v^{n} + {}_{t}p^{01}_{x} v^{n} + {}_{t}p^{02}_{x} v^{n} &= v^{n} \\
    \int^{n}_{0} {}_{t}p^{00}_{x} v^{n} + {}_{t}p^{01}_{x} v^{n} + {}_{t}p^{02}_{x} v^{n} &= \int^{n}_{0} v^n \\
    \ddot{a}^{00}_{x\enclose{actuarial}{n}}
    + \ddot{a}^{01}_{x\enclose{actuarial}{n}}
    + \ddot{a}^{02}_{x\enclose{actuarial}{n}}
    &= \ddot{a}_{\enclose{actuarial}{n}} \\
    \\
    \therefore \ddot{a}^{00}_{x} + \ddot{a}^{01}_{x} + \ddot{a}^{02}_{x} &= \ddot{a}_{\enclose{actuarial}{\infty}} \\
\end{aligned}
$$

!!! Warning

    It is a common mistake to forget the probability of staying in the same state, as most state diagrams do not typically include it.

Recall from FAM-L that **annuities and assurances** are related to one another. In a muli-state setting, the relationship only holds true if the target assurance is **transitioning into an absorbing state** $k$. Consider the same 3-state model from before:

$$
\begin{aligned}
    A^{ik} &= 1 - d \cdot \sum_{j \ne k} \ddot{a}^{ij}_{x} \\
    \therefore A^{02}_{x} &= 1 - d \cdot (\ddot{a}^{00}_{x} + \ddot{a}^{01}_{x}) \\
    \therefore A^{12}_{x} &= 1 - d \cdot (\ddot{a}^{10}_{x} + \ddot{a}^{11}_{x}) \\   
\end{aligned}
$$

#### **Sorjourn Annuity**

The definition of "Sorjourn" is to **stay temporarily**. Thus, a Sojourn annuity is an annuity that pays a benefit while the insured **stays in a specific state**, given that they are already in that state (hence stay). It's acturial value is denoted by $\ddot{a}^{\bar{ii}}_{x}$.

They are usually used to calculate the **PV of premiums** as premiums are usually only payable while the insured is healthy. Consider the following example:

* 3-year Discrete Temporary Annuity
* Premium payable at the beginning of the year **while in state 0**
* Insured is currently in state 0

<!-- Obtained from ALTAM textbook -->
![Perm Disability](Assets/3.%20Multi%20State%20Models.md/Perm%20Disability%20Model.png){.center}

$$
\begin{array}{|c|c|c|c|}
\hline
    \text{Policy Year End}
        & \text{State}
        & \text{Probability} 
        & \text{PV Benefit} \\
\hline
    0
        & \text{0}
        & -
        & B \\
\hline
    1
        & \text{0 - 0}
        & p^{\bar{00}}_{x}
        & Bv \\
\hline
    1
        & \text{0 - 1}
        & p^{01}_{x}
        & 0 \\
\hline
    1
        & \text{0 - 2}
        & p^{02}_{x}
        & 0 \\
\hline
    2
        & \text{0 - 0 - 0}
        & p^{\bar{00}}_{x} \cdot p^{\bar{00}}_{x+1}
        & Bv^{2} \\
\hline
    2
        & \text{0 - 0 - 1}
        & p^{\bar{00}}_{x} \cdot p^{01}_{x+1}
        & 0 \\
\hline
    2
        & \text{0 - 0 - 2}
        & p^{\bar{00}}_{x} \cdot p^{02}_{x+1}
        & 0 \\
\hline
    2
        & \text{0 - 1 - 1}
        & p^{01}_{x} \cdot p^{\bar{11}}_{x+1}
        & 0 \\
\hline
    2
        & \text{0 - 1 - 2}
        & p^{01}_{x} \cdot p^{12}_{x+1}
        & 0 \\
\hline
    2
        & \text{0 - 2 - 2}
        & p^{02}_{x} \cdot p^{\bar{22}}_{x+1}
        & 0 \\
\hline
\end{array}
$$

!!! Tip

    Since the insured **already starts in the premium paying state**, there is a cashflow at time 0 which was not seen in the other examples.

$$
\begin{aligned}
    \ddot{a}^{\bar{00}}_{x\enclose{actuarial}{3}}
    &= B + p^{\bar{00}}_{x} \cdot Bv + p^{\bar{00}}_{x} \cdot p^{\bar{00}}_{x+1} \cdot Bv^{2} \\
    &= B + p^{\bar{00}}_{x} \cdot Bv + {}_{2}p^{\bar{00}}_{x} \cdot Bv^{2}
\end{aligned}
$$

More generally, they can be expressed as:

$$
\begin{aligned}
    \ddot{a}^{\bar{00}}_{x}
    &= \sum^{\infty}_{0} v^{t} {}_{t}p^{\bar{ii}}_{x} \\
    \\
    \bar{a}^{\bar{00}}_{x}
    &= \int^{\infty}_{0} e^{-\delta t} {}_{t}p^{\bar{ii}}_{x}
\end{aligned}
$$

!!! Tip

    The general multi-state annuity can be expressed in the form of a Sojourn annuity:

    $$
        \bar{a}^{ij}_{x}
        = \int^{\infty}_{0} {}_{t}p^{ik}_{x} \mu^{kj}_{x+t} \cdot e^{-\delta t} \bar{a}^{\bar{jj}}_{x+t}
    $$

    It represents the probability that the policyholder transitions into state $j$ and **receives an annuity** at that moment that pays for as long as they remain in that state. This expression is **more flexible** than the original expression because it allows us to **specify the duration** of payments.
    
    In the above example, a **whole life annuity** is used, which implies that the benefit will be paid **for as long as** they are in the state. However, a **temporary annuity** can be specified instead, which implies that the benefit will be paid a **limited period of time** EACH TIME the policyholder enters that state:

    $$
        \int^{\infty}_{0} \sum {}_{t}p^{ik}_{x} \mu^{kj}_{x+t} \cdot e^{-\delta t} \bar{a}^{\bar{jj}}_{x+t:\enclose{actuarial}{n}}
    $$

    Note that the expression is typically what we see of an Assurance, rather than an annuity, which is why it might be confusing to grasp.

!!! Warning

    Note that the final expression in the above example is **NOT equivalent** to a temporary multi-state annuity:

    $$
        \bar{a}^{ij}_{x:\enclose{actuarial}{n}}
        \ne \int^{\infty}_{0} {}_{t}p^{ik}_{x} \mu^{kj}_{x+t} \cdot e^{-\delta t} bar{a}^{\bar{jj}}_{x+t:\enclose{actuarial}{n}}
    $$

    The LHS corresponds to a policy that lasts for $n$ years while the RHS corresponds to a policy that pays for only the first $n$ years on each entry into the state. 


#### **Woolhouse Approximation**

Recall that the Woolhouse Approximation was used to approximate Continuous or Monthly annuities from their yearly discrete variants. Skipping the formal proof, the **three term woolhouse approximation** in a multi-state setting is as follows:

$$
\begin{aligned}
    \ddot{a}^{(m)ij}_{x} &= \ddot{a}^{ij}_{x} + \frac{m^{2} - 1}{12m^{2}} \mu^{ij}_{x}(t) \\
    \\
    \ddot{a}^{(m)\bar{ii}}_{x}
    &= \ddot{a}^{\bar{ii}}_{x} - \frac{m-1}{2m} - \frac{m^{2} - 1}{12m^{2}} [\mu^{i \tau}_{x}(t) + \delta]
\end{aligned}
$$

!!! Info

    The above is not a typo; there is a different formula for the Soujourn and Non-Sourjourn annuities. Both are provided on the formula sheet.

!!! Tip

    The above can then be converted into a Continuous or Temporary annuity approximation using the usual methods.

    Despite the non-sojourn annuity having **only two terms**, it is still known as the three term woolhouse approximation. If asked for the two term approximation, **drop the last term**. The approximation simply equal to the existing value.

**Sojourn** approximations are closest to the typical life annuity covered. Thus, it is expected that the sojourn approximation is **almost identical** to the original approximation.

!!! Note

    The force term is meant to be of the **OPPOSITE of the annuity event**.

    In FAM-L, the force was the force of dying, opposite of the annuity benefit which pays while living. For a sojourn annuity, the opposite of staying in the same state is a **transition to any other state**.

**Non-sojourn** approximations are seemingly similar to the usual approximations, but there are **multiple differences**:

1. There are only two terms instead of three (Usual second term is missing)
2. The sign is flipped on the 'third' term ('+' instead of '-')
3. The force term is of the SAME annuity event

### **Exponential Shortcut**

Recall from FAM-L that if the force of mortality is constant, then the resulting assurance and annuity factors can be **simplified** as well. Applying it in a multi-state context would result in the following:

$$
\begin{aligned}
    \bar{a}^{ii}_{x}
    &= \int^{\infty}_{0} e^{-\delta t} {}_{t}p^{ii}_{x} \\
    &= \int^{\infty}_{0} e^{-\delta t} e^{- \mu^{i \tau}_{x} t} \\
    &= \int^{\infty}_{0} e^{- (\delta +\mu^{i \tau})t} \\
    &= \left[- \frac{e^{- (\delta +\mu^{i \tau})t}}{\delta +\mu^{0 \tau}} \right]^{\infty}_{0} \\
    &= -\frac{e^{-\infty}}{\delta +\mu^{i \tau}} - -\frac{e^{0}}{\delta +\mu^{i \tau}} \\
    &= \frac{1}{\mu^{i \tau} + \delta} \\
    \\
    \bar{A}^{ij \text{(Direct)}}_{x}
    &= \int^{\infty}_{0} e^{-\delta t} {}_{t}p^{ii}_{x} \mu^{ij}_{x} \\
    &= \mu^{ij}_{x} \int^{\infty}_{0} e^{-\delta t} e^{- \mu^{i \tau}_{x} t} \mu^{ij}_{x} \\
    &= \mu^{ij}_{x} \int^{\infty}_{0} e^{- (\delta +\mu^{i \tau})t} \\
    &= \dots \\
    &= \frac{\mu^{ij}}{\mu^{ij} + \delta}
\end{aligned}
$$

There are **additional conditions** required for the above to be used, as the model must **mimic the conditions of the original survival model**:

* **Annuity**: It must not be possible to re-enter the original state
* **Assurance**: The transition must be direct from $i$ to $j$, no intermediate states

!!! Warning

    The shortcut does NOT apply to $\bar{a}^{ij}_{x}$ or $\bar{A}^{ii}_{x}$. Those quantities have to be calculated using first principles. A good way to remember is to put the original shortcut into a **two-state alive-dead model** context.

!!! Tip

    There is **no need to memorize** a seperate formula for TA - plug the shortcut into the WL to TA formula to get the simplified TA expression.

    Additionally, since the force is constant for all ages, the above formulas apply to all ages as well:

    $$
    \begin{aligned}
        \bar{a}^{ii}_{x} &= \bar{a}^{ii}_{x+s} = \frac{1}{\mu^{i \tau} + \delta} \\
        \bar{A}^{ij \text{(Direct)}}_{x} &= \bar{A}^{ij \text{(Direct)}}_{x+s} = \frac{\mu^{ij}}{\mu^{ij} + \delta}
    \end{aligned}
    $$

### **Reserves**

Recall that reserves are calculated as the EPV of the net outflows each period. In a multi-state setting, the **outflows are dependent on the state** of the insured at the time of valuation. Thus, the reserve must reflect **two dimensions** - both time and state.

$$
    {}_{t}V^{(i)} = \text{EPV(Benefits)}_{t}^{i}
                  + \text{EPV(Expenses)}_{t}^{i}
                  - \text{EPV(Premiums)}_{t}^{i}
$$

!!! Tip

    Note that some terms may **naturally evaluate to 0**. For instance,

    * **Premiums may not be payable** while in that state
    * **Certain benefits may not payable** in that state

#### Thiele's DE

Reserves for a continuous assurance or annuity can be instead calculated using **Thiele's Differential Equation**:

$$
\begin{aligned}
    \frac{d}{dt} {}_{t}V^{i}
    &= \delta_{t} \cdot {}_{t}V^{i}
    - \underbrace{\left(B_{t}^{i} + e_{t}^{i} - P_{t}^{i} \right)}_{\text{Net In-State Outgo}}
    - \sum_{j \ne i} \mu^{ij}_{x}(t) \cdot (b^{ij} + {}_{t}V^{j} - {}_{t}V^{i})
\end{aligned}
$$

!!! Tip

    If one of the target states is absorbing (EG. Death), then the reserve for that state is 0 as there are no more future payments.

Similar to before, the DE is trying to **approximate the change in the reserve**:

* Reserve **earns interest**
* **Released** to pay off expected *net* benefits and expenses (while in state & upon transition)
* Form a new reserve for *every possible* resulting state

!!! Warning

    Do NOT mix up the two benefit variables:

    * **Big B**: **Rate** of benefit payment **while in** the current state
    * **Small B**: **Lump Sum** benefit payment **upon transition** into other state

Similarly, the DE can be solved using **Euler's Method**. Thiele's DE usually uses the **backward variation** instead:

$$
\begin{aligned}
    \frac{d}{dt} {}_{t}V^{i}
    &= \delta_{t} \cdot {}_{t}V^{i} - B - \sum_{j \ne i} \mu^{ij}_{x}(t) \cdot (b^{ij} + {}_{t}V^{j} - {}_{t}V^{i})
    \\
    \frac{{}_{t}V^{i} - {}_{t-h}V^{i}}{h}
    &= \delta_{t} \cdot {}_{t}V^{i} - B - \sum_{j \ne i} \mu^{ij}_{x}(t) \cdot (b^{ij} + {}_{t}V^{j} - {}_{t}V^{i})
    \\
    {}_{t}V^{i}
    &= {}_{t-h}V^{i} + h \cdot
    \left(\delta_{t} \cdot {}_{t}V^{i} - B
    - \sum_{j \ne i} \mu^{ij}_{x}(t) \cdot (b^{ij} + {}_{t}V^{j} - {}_{t}V^{i}) \right)
\end{aligned}
$$

#### **Recursion**

One method of determining the reserve for the euler's method is to use **Recursion**. It follows the same intuition as before, with the key difference having to account for the **multiple possibilities** for the expected benefits and ending reserve.

$$
\begin{aligned}
    ({}_{t}V^{i} + P - e - B^{\text{In State}})(1+i)
    &= \sum p^{ik}_{x+t} \cdot B^{\text{Upon Transition}}
    + \sum p^{ik}_{x+t} \cdot {}_{t}V^{k}
\end{aligned}
$$

### **Impact Assessment**

For most multi-state models, the policy does not terminate upon transitioning to another state. Thus, when assessing the impact of a change in probability on EPVs, it is necessary to consider two levels of impact:

* **First Order Impact**: Increasing the probability of transitioning to a specified state will increase the EPV of cashflows upon transitioning to or being paid while in that state
* **Second Order Impact**: *From that new state*, the probability of transitioning into other states maybe higher or lower, thus causing the EPV of certain cashflows to change as well
