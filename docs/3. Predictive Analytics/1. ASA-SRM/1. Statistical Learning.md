# **Introduction to Statistical Learning**

## **Estimation VS Prediction**

The primary focus of traditional statistics lies in **Estimation**. However, the focus of statistical learning is **Prediction**. Both are **approximation methods** and although they are used interhchangeably in layman terms, there is a **technical difference** between the two:

<center>

|                 **Estimation**                  |                  **Prediction**                   |
| :---------------------------------------------: | :-----------------------------------------------: |
| Approximating a **parameter** of a distribution | Approximating a **realization** of a distribution |
|                 Non-stochastic                  |                    Stochastic                     |

</center>

For instance, given that $X \sim \text{Dist}(\theta)$:

* $X$ is the distribution
* $\theta$ is a parameter of the distribution (to be estimated)
* $x_{i}$ is a realization of the distribution (to be predicted)

## **Overview of key elements**

There are two main components to a prediction problem:

<center>

|  **Dependent Variable**  | **Independent Variable** |
| :----------------------: | :----------------------: |
| Variable to be predicted | Variable used to predict |
|          Only 1          |    May have multiple     |
|     Output Variable      |      Input Variable      |
|         $y_{i}$          |     $x_{i}, x_{i,j}$     |

</center>

!!! Note

    Observations typically record the two variables together ($y_{i}$, $x_{i}$). In the case where there are multiple independent variables ($x_{i,j}$), $i$ represents the observation while $j$ represents the independent variable.

Within the above, they are further split by their nature:

<center>

| **Quantitative Variable** |   **Qualitative Variable**    |
| :-----------------------: | :---------------------------: |
|     Continuous Values     |      Discrete Categories      |
|      EG. 3.14, 1.849      | EG. North, South, East & West |
|        Regression         |        Classification         |

</center>

!!! Note

    Categorical variables are more generally represented by a **discrete number**. For instance:

    * True (1), False (0)
    * North (0), East (1), South (2), West (4)

    If there the **order of the categories** are important, then they are known as **Ordinal variables**. If not, they are known as **Nominal Variables**.

Then there are two types of statistical learning:

<center>

|           **Supervised**            |         **Unsupervised**         |
| :---------------------------------: | :------------------------------: |
| Has a specified Indpendent Variable |     No Independent Variable      |
|   To identify what influences $y$   | To identify patterns in the data |
|        EG. Linear Regression        | EG. Principal Component Analysis |

</center>

Within Supervised learning methods, it can be further broken down into two types:

<center>

|                 **Parametric**                  |            **Non-parametric**             |
| :---------------------------------------------: | :---------------------------------------: |
| User specified relationship between $y$ and $x$ |         No specified relationship         |
|  **Equation with parameters** to be estimated   | Algorithmic method with **no parameters** |
|              EG. Linear Regression              |            EG. Decision Trees             |

</center>

Predictor comes with additional uncertaitnty due to the stochastic nature (on top of uncertaintity in the estimation parameters)
EVen with increasing sample size, the prediction does not shrink to 0 (Irreducible randomness)
